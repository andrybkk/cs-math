#set page(
  paper: "a4", 
  margin: (x: 2cm, y: 2.5cm), 
  numbering: "1 / 1"
)

#set text(
  font: "New Computer Modern",
  size: 12pt,
  lang: "ru"
)

#set par(
  justify: true,
  leading: 0.65em
)

#show heading: set text(fill: blue.darken(20%))
#show heading: set text(weight: "bold")

#show heading.where(level: 1): it => [
  #set text(size: 24pt)
  #v(1em)
  #it
  #v(-20pt)
  #line(length: 100%, stroke: 1pt + blue.darken(20%))
]

#show heading.where(level: 2): set text(size: 18pt)

#let note(title, body) = rect(
  fill: blue.lighten(90%),
  stroke: blue.darken(20%) + 1pt,
  radius: 4pt,
  width: 100%,
  inset: 12pt
)[
  *#title* \
  #body
]

#let ax(id, body) = grid(
  columns: (30pt, 1fr),
  gutter: 10pt,
  v(0em) + [*#id*],
  body
)

#let axiom_block(title, content) = block(
  width: 100%,
  stroke: 0.5pt + gray,
  radius: 3pt,
  inset: 12pt,
  fill: rgb("#fafafa")
)[
  #set text(size: 11pt)
  #align(center)[#text(weight: "bold", size: 13pt)[#title]]
  #v(0.4em)
  #content
]
// Заголовки
#show heading: set text(fill: rgb("#0055aa"))

= 1. Оценка сложности алгоритма по времени (Time Complexity)

В алгоритмах нас волнует не _секунды_ (они зависят от железа), а _количество операций_ в зависимости от размера входных данных $N$.

== Асимптотические нотации

Мы используем "O-большое" ($O$), чтобы оценить *худший случай* (верхняя граница).

Определение:
$ f(n) = O(g(n))$ iff $exists C > 0, n_0 > 0 : forall n >= n_0, |f(n)| <= C dot |g(n)| $

Простыми словами: начиная с какого-то $n$, наш алгоритм работает не медленнее, чем $g(n)$, умноженная на константу.

*Важные правила:*
1. *Константы отбрасываются:* $O(2n) => O(n)$, $O(500) => O(1)$.
2. *Младшие члены отбрасываются:* $O(n^2 + n + 100) => O(n^2)$.

== Основные классы сложности (от лучшего к худшему)

#table(
  columns: (auto, auto, 2fr),
  inset: 10pt,
  align: horizon,
  [*Нотация*], [*Название*], [*Пример*],
  [$O(1)$], [Константная], [Взять элемент массива по индексу, `map[key]` (в среднем).],
  [$O(log n)$], [Логарифмическая], [Бинарный поиск (`std::lower_bound`), операции в `std::set`.],
  [$O(n)$], [Линейная], [Проход по массиву циклом `for`, поиск минимума.],
  [$O(n log n)$], [Линеарифическая], [Быстрые сортировки (`MergeSort`, `HeapSort`, `std::sort`).],
  [$O(n^2)$], [Квадратичная], [Вложенные циклы, `BubbleSort`, `InsertionSort`.],
  [$O(2^n)$], [Экспоненциальная], [Перебор всех подмножеств (рюкзак брутфорсом).],
  [$O(n!)$], [Факториальная], [Перебор перестановок (задача коммивояжера).]
)

= 2. Оценка сложности алгоритма по памяти (Space Complexity)

Оцениваем, сколько *дополнительной* памяти (Auxiliary Space) требует алгоритм относительно входных данных.

*Важные моменты:*
+ *Переменные:* $O(1)$ (если их фиксированное число).
+ *Массивы/Векторы:* $O(n)$, если создаем копию данных.
+ *Рекурсия (Стек вызовов):* Это часто забывают! Глубина рекурсии жрет память.
  - Например, `quicksort` в худшем случае займет $O(n)$ доп. памяти
  - В сбалансированном дереве — $O(log n)$.

== Примеры оценки памяти

1. *Сортировка пузырьком:*
   Мы меняем элементы местами внутри массива (`swap`). Доп. память не нужна.
   $S(n) = O(1)$ (In-place).

2. *Сортировка слиянием (Merge Sort):*
   Нам нужен дополнительный буфер для слияния частей.
   $S(n) = O(n)$.

3. *Рекурсивный Фибоначчи (наивный):*
   ```cpp
   int fib(int n) {
       if (n <= 1) return n;
       return fib(n-1) + fib(n-2); // максимальная глубина стека - n; S(n) = O(n)
   }
   ```

#pagebreak()
= 3. Сортировка вставками (Insertion Sort)

Самый интуитивный алгоритм. Именно так люди сортируют карты в руке: берем новую карту и пихаем ее в нужное место среди уже отсортированных.

== Принцип работы

Мы делим массив на две части:
1. *Отсортированная часть* (слева). Изначально там только один элемент $A[0]$.
2. *Неотсортированная часть* (справа).

На каждом шаге мы берем первый элемент из _неотсортированной_ части и "вставляем" его на правильное место в _отсортированную_, сдвигая элементы, которые больше него, вправо.

== Инвариант цикла
В начале итерации $i$ подмассив $A[0 .. i-1]$ состоит из элементов, которые были в этом диапазоне изначально, но теперь они *отсортированы*.

== Реализация (C++)

```cpp
void insertionSort(vector<int>& arr) {
    int n = arr.size();
    for (int i = 1; i < n; i++) {
        int key = arr[i]; // Элемент, который вставляем
        int j = i - 1;

        // Сдвигаем элементы arr[0..i-1], которые больше key,
        // на одну позицию вправо
        while (j >= 0 && arr[j] > key) {
            arr[j + 1] = arr[j];
            j = j - 1;
        }
        arr[j + 1] = key; // Вставляем на освободившееся место
    }
}
```

#pagebreak()
== Анализ сложности

=== Время (Time Complexity)

+ *Худший случай (Worst Case):* Массив отсортирован в обратном порядке.
  Для каждого элемента $i$ нам придется делать $i$ сравнений и сдвигов.
  $ sum_(i=1)^(n-1) i = frac(n(n-1), 2) approx O(n^2) $

+ *Лучший случай (Best Case):* Массив уже отсортирован.
  Внутренний цикл `while` ни разу не выполнится (условие `arr[j] > key` сразу ложно). Мы просто пройдемся по массиву.
  $ O(n) $

+ *Средний случай (Average Case):*
  В среднем приходится сдвигать половину элементов слева.
  $ O(n^2) $

=== Память (Space Complexity)
$O(1)$. Сортировка происходит "на месте" (in-place). Нам нужна только одна доп. переменная `key`.

== Свойства алгоритма

+ *Устойчивость (Stable):* Да. Мы не меняем порядок равных элементов (условие `arr[j] > key` строгое, если элементы равны, сдвига не будет, и новый встанет _после_ равного).
+ *Адаптивность (Adaptive):* Да. Если массив "почти отсортирован", алгоритм работает очень быстро (близко к $O(n)$).
+ *Online-алгоритм:* Да. Мы можем сортировать данные по мере их поступления (по одному).

== Зачем это нужно?

Казалось бы, $O(n^2)$. Но Insertion Sort — хорош на *маленьких массивах*.

Почему:
1. Очень простой код (мало оверхеда).
2. Хорошо работает с кэшем процессора (последовательный доступ к памяти).

*Реальный кейс:* В `std::sort` (C++) или `pdqsort` (Go/Rust) используется гибридный подход. Когда рекурсия QuickSort делит массив на куски размером меньше 16-32 элементов, она переключается на Insertion Sort, потому что на таких объемах он быстрее асимптотически крутых алгоритмов.

#pagebreak()
= 4. Сортировка слиянием (Merge Sort)

Это алгоритм класса "Разделяй и Властвуй". Он гарантирует отличную скорость даже на самых плохих данных, но требует "жертв" по памяти.

== Визуализация процесса
Мы дробим массив пополам, пока не получим кучу одиночных элементов (а один элемент всегда отсортирован). Потом мы начинаем склеивать (сливать) их обратно, но уже в правильном порядке.

#align(center)[
  #let box-style(content) = rect(
    fill: rgb("#e1f5fe"),
    stroke: rgb("#0277bd"),
    radius: 4pt,
    inset: 8pt,
    content
  )
  #let arrow = text(size: 14pt, fill: gray)[$arrow.b$]

  #box-style[*[ 38, 27, 43, 3 ]*] \
  #v(5pt) #arrow #v(5pt)

  #grid(
    columns: 2,
    gutter: 20pt,
    box-style([38, 27]),
    box-style([43, 3])
  )
  #v(5pt) #arrow #v(5pt)

  #grid(
    columns: 4,
    gutter: 10pt,
    box-style([38]), box-style([27]), box-style([43]), box-style([3])
  )
  #v(5pt) 
  $text(weight: "bold", "Merge")$
  #v(5pt)

  // Уровень 4: Слияние пар
  #grid(
    columns: 2,
    gutter: 20pt,
    box-style([27, 38]), // 27 < 38
    box-style([3, 43])   // 3 < 43
  )
  #v(5pt) #arrow #v(5pt)

  // Уровень 5: Финал
  #box-style[*[ 3, 27, 38, 43 ]*]
]

== Алгоритм

1. *Divide (Разделение):* Находим середину массива и рекурсивно вызываем сортировку для левой и правой половин.
2. *Conquer (Властвование):* Если размер подмассива равен 1 — он уже отсортирован. Возвращаем его.
3. *Combine (Слияние):* Берем два отсортированных массива и сливаем их в один общий с помощью *двух указателей*.

== Реализация (С++)

```cpp
// Функция слияния двух отсортированных частей
void merge(vector<int>& arr, int left, int mid, int right) {
    // Временные векторы (жрут память!)
    vector<int> L(arr.begin() + left, arr.begin() + mid + 1);
    vector<int> R(arr.begin() + mid + 1, arr.begin() + right + 1);

    int i = 0, j = 0, k = left;

    // Сравниваем головы двух массивов и берем меньший
    while (i < L.size() && j < R.size()) {
        if (L[i] <= R[j]) { // <= важно для устойчивости (Stable)
            arr[k++] = L[i++];
        } else {
            arr[k++] = R[j++];
        }
    }

    // Докидываем остатки, если они есть
    while (i < L.size()) arr[k++] = L[i++];
    while (j < R.size()) arr[k++] = R[j++];
}

void mergeSort(vector<int>& arr, int left, int right) {
    if (left >= right) return; // Базовый случай

    int mid = left + (right - left) / 2;
    mergeSort(arr, left, mid);      // Сортируем левую часть
    mergeSort(arr, mid + 1, right); // Сортируем правую часть
    merge(arr, left, mid, right);   // Сливаем
}
```

#pagebreak()
= 5. Быстрая сортировка (Quick Sort)

Один из самых эффективных алгоритмов сортировки общего назначения. Разработан Тони Хоаром в 1960 году. Относится к классу алгоритмов "Разделяй и властвуй" (Divide and Conquer).

В отличие от сортировки слиянием, где основной работой является объединение отсортированных частей, в быстрой сортировке основная вычислительная сложность приходится на этап *разделения* (partitioning).

== Принцип работы

Алгоритм состоит из трех этапов:

1. *Выбор опорного элемента (Pivot):* Из массива выбирается один элемент. От его выбора зависит эффективность работы алгоритма.
2. *Разбиение (Partition):* Перераспределение элементов в массиве таким образом, что:
   - Все элементы _меньше_ опорного помещаются слева от него.
   - Все элементы _больше_ опорного помещаются справа.
   - Опорный элемент занимает свое окончательное (отсортированное) положение. \ (в Хоара необязательно)
3. *Рекурсия:* Рекурсивный запуск алгоритма для левого и правого подмассивов (исключая опорный элемент).

== Визуализация этапа Partition

Рассмотрим массив, где в качестве опорного элемента (Pivot) выбран первый элемент (*4*).

#align(center)[
  #let box-style(content, fill-color) = rect(
    fill: fill-color,
    stroke: black,
    radius: 2pt,
    width: 20pt,
    height: 20pt,
    align(center + horizon, content)
  )
  #let arrow = text(size: 14pt)[$arrow.b$]

  // Исходное состояние
  *1. Исходный массив (Pivot = 4):* \
  #v(5pt)
  #grid(
    columns: 7,
    gutter: 5pt,
    box-style([*4*], rgb("#ffcc80")), // Pivot
    box-style([7], white),
    box-style([1], white),
    box-style([3], white),
    box-style([2], white),
    box-style([6], white),
    box-style([5], white)
  )
  #v(5pt) #arrow #v(5pt)

  *2. Процесс разделения:* \
  Перемещаем элементы $<4$ влево, $>4$ вправо. \
  #v(5pt)
  #grid(
    columns: 7,
    gutter: 5pt,
    box-style([3], rgb("#e1f5fe")),
    box-style([1], rgb("#e1f5fe")),
    box-style([2], rgb("#e1f5fe")),
    box-style([*4*], rgb("#ffcc80")), // Pivot на месте
    box-style([7], rgb("#fce4ec")),
    box-style([6], rgb("#fce4ec")),
    box-style([5], rgb("#fce4ec"))
  )
  #v(5pt)
  Теперь 4 находится на своем месте. Рекурсивно сортируем синюю и розовую части.
]

== Реализация (C++)

В данной реализации используется схема разбиения Ломуто (Lomuto partition scheme), где опорным элементом выбирается последний элемент.

```cpp
// Функция разделения массива
int partition(vector<int>& arr, int low, int high) {
    int pivot = arr[high]; // Опорный элемент
    int i = (low - 1);     // Индекс меньшего элемента

    for (int j = low; j <= high - 1; j++) {
        // Если текущий элемент меньше или равен опорному
        if (arr[j] <= pivot) {
            i++;
            swap(arr[i], arr[j]);
        }
    }
    // Ставим опорный элемент на правильную позицию
    swap(arr[i + 1], arr[high]);
    return (i + 1);
}

void quickSort(vector<int>& arr, int low, int high) {
    if (low < high) {
        // pi - индекс разделения (partitioning index)
        int pi = partition(arr, low, high);

        // Рекурсивно сортируем элементы до и после разделения
        quickSort(arr, low, pi - 1);
        quickSort(arr, pi + 1, high);
    }
}
```

#pagebreak()

== Реализация схемы Хоара (C++)

Данный вариант эффективнее схемы Ломуто по количеству операций записи в память (swap), так как обмен происходит только тогда, когда это действительно необходимо (инверсия относительно pivot).

```cpp
int partitionHoare(std::vector<int>& arr, int low, int high) {
    // В качестве опорного выбираем первый элемент (для простоты)
    // На практике лучше брать arr[(low + high) / 2]
    int pivot = arr[low];
    int i = low - 1;
    int j = high + 1;

    while (true) {
        // Сдвигаем левый указатель вправо, пока элементы меньше pivot
        do {
            i++;
        } while (arr[i] < pivot);

        // Сдвигаем правый указатель влево, пока элементы больше pivot
        do {
            j--;
        } while (arr[j] > pivot);

        // Если указатели пересеклись, разбиение завершено
        if (i >= j)
            return j;

        // Иначе меняем элементы местами
        std::swap(arr[i], arr[j]);
    }
}

void quickSortHoare(std::vector<int>& arr, int low, int high) {
    if (low < high) {
        // Получаем индекс разделения
        int p = partitionHoare(arr, low, high);

        // Важно: в схеме Хоара элемент p включается в ЛЕВУЮ часть
        quickSortHoare(arr, low, p);
        quickSortHoare(arr, p + 1, high);
    }
}
```
#pagebreak()

== Анализ сложности

=== Время (Time Complexity)

Скорость работы критически зависит от выбора опорного элемента и структуры входных данных.

+ *Средний и лучший случай:* $O(N log N)$.
  Это достигается, когда опорный элемент делит массив на две примерно равные части. Глубина рекурсии составляет $log_2 N$.

+ *Худший случай:* $O(N^2)$.
  Происходит, если на каждом этапе массив делится на части размером $1$ и $N-1$.
  _Пример:_ Массив уже отсортирован (в прямом или обратном порядке), а в качестве Pivot всегда берется первый или последний элемент.

=== Память (Space Complexity)

Алгоритм работает *in-place* (без выделения дополнительного массива), но расходует стековую память на рекурсивные вызовы.

* *Средний случай:* $O(log N)$.
* *Худший случай:* $O(N)$ (при деградации до $O(N^2)$).

== Стратегии выбора Pivot

Чтобы избежать худшего случая ($O(N^2)$), применяются следующие эвристики:
1. *Случайный выбор (Randomized QuickSort):* Pivot выбирается рандомно. Это делает вероятность худшего случая крайне низкой.
2. *Медиана трех (Median-of-three):* В качестве Pivot берется медиана между первым, средним и последним элементами.

== Свойства алгоритма

+ *Неустойчивость (Unstable):* Да. В процессе разделения относительный порядок равных элементов может быть нарушен.
+ *In-place:* Да. Не требует $O(N)$ дополнительной памяти, как Merge Sort.
+ *Кэш-локальность:* Высокая. Quick Sort работает быстрее Merge Sort и Heap Sort на практике, так как последовательно обращается к памяти, эффективно используя кэш процессора.

=== Примечание: Схема Хоара vs Схема Ломуто

В коде выше использована *схема Ломуто* (однонаправленный проход). Она проще в реализации и гарантирует, что после этапа `partition` опорный элемент (Pivot) встает на свое *финальное отсортированное место*.

Однако оригинальная *схема Хоара* (два указателя, движущихся навстречу друг другу) работает иначе:
1. Она эффективнее (делает в среднем в 3 раза меньше обменов).
2. *Важно:* После разбиения Хоара опорный элемент *не обязательно* оказывается на своем финальном месте. Функция разбиения возвращает индекс, разделяющий массив на две части (элементы $<=$ pivot и элементы $>=$ pivot), но сам pivot может находиться где угодно внутри соответствующей части.

= 6. Сортировка подсчетом (Counting Sort)

Алгоритм сортировки, применимый, когда входные данные являются целыми числами в ограниченном диапазоне. Основная идея — подсчитать, сколько раз встречается каждый элемент, и на основе этого определить его позицию в отсортированном массиве.

== Визуализация процесса

Пусть дан массив чисел в диапазоне от 0 до 5.

#align(center)[
  #let box-style(content, fill-color) = rect(
    fill: fill-color,
    stroke: black,
    radius: 2pt,
    width: 25pt,
    height: 25pt,
    align(center + horizon, content)
  )
  #let label-style(content) = text(size: 8pt, fill: gray)[#content]

  // 1. Входные данные
  *1. Входной массив (Input):* \
  #v(5pt)
  #grid(
    columns: 7,
    gutter: 3pt,
    box-style([1], white), box-style([4], white), box-style([1], white),
    box-style([2], white), box-style([7], white), box-style([5], white), box-style([2], white)
  )
  #v(10pt)

  *2. Массив подсчета (Count Array):* \
  Индексы соответствуют значениям элементов. Значения — количеству их вхождений. \
  #v(5pt)
  #grid(
    columns: 8,
    gutter: 3pt,
    // Значения
    box-style([0], rgb("#e0e0e0")), box-style([2], rgb("#fff9c4")), box-style([2], rgb("#fff9c4")),
    box-style([0], rgb("#e0e0e0")), box-style([1], rgb("#fff9c4")), box-style([1], rgb("#fff9c4")),
    box-style([0], rgb("#e0e0e0")), box-style([1], rgb("#fff9c4")),
    // Индексы
    label-style([0]), label-style([1]), label-style([2]), label-style([3]),
    label-style([4]), label-style([5]), label-style([6]), label-style([7])
  )
  #v(10pt)

  *3. Восстановление (Output):* \
  Раскладываем числа согласно их количеству. \
  #v(5pt)
  #grid(
    columns: 7,
    gutter: 3pt,
    box-style([1], rgb("#e1f5fe")), box-style([1], rgb("#e1f5fe")),
    box-style([2], rgb("#e1f5fe")), box-style([2], rgb("#e1f5fe")),
    box-style([4], rgb("#e1f5fe")), box-style([5], rgb("#e1f5fe")), box-style([7], rgb("#e1f5fe"))
  )
]

== Алгоритм (Стабильная версия)

Для сохранения свойства устойчивости (stability) алгоритм усложняется:

1. *Подсчет частот:* Создаем массив `count`, где `count[i]` — число вхождений элемента `i`.
2. *Префиксные суммы:* Модифицируем `count`, чтобы `count[i]` содержал количество элементов, _меньших либо равных_ `i`. Это фактически позиция последнего вхождения числа `i` в выходном массиве.
3. *Расстановка:* Проходим по исходному массиву *с конца*. Для каждого числа `x` помещаем его в выходной массив на позицию `count[x] - 1` и уменьшаем `count[x]`.

#pagebreak()
== Реализация (C++)

```cpp
void countingSort(std::vector<int>& arr) {
    if (arr.empty()) return;

    // 1. Поиск диапазона
    int max_val = *std::max_element(arr.begin(), arr.end());
    int min_val = *std::min_element(arr.begin(), arr.end());
    int range = max_val - min_val + 1;

    // 2. Массив частот
    std::vector<int> count(range, 0);
    std::vector<int> output(arr.size());

    // Подсчет вхождений
    for (int num : arr) {
        count[num - min_val]++;
    }

    // 3. Префиксные суммы (накопление)
    // count[i] теперь хранит позицию элемента
    for (int i = 1; i < range; i++) {
        count[i] += count[i - 1];
    }

    // 4. Построение выходного массива (идем с конца для устойчивости)
    for (int i = arr.size() - 1; i >= 0; i--) {
        int num = arr[i];
        int index_in_count = num - min_val;
        output[count[index_in_count] - 1] = num;
        count[index_in_count]--;
    }

    // Копируем обратно
    arr = output;
}
```

=== Зачем нужен `num - min_val`?

1. *Поддержка отрицательных чисел:* Индексы массива в C++ начинаются с 0. Если в данных есть число $-5$, мы не можем обратиться к `count[-5]`. Сдвиг переносит минимальный элемент в индекс 0.
2. *Оптимизация памяти:* Если сортируем числа в диапазоне $[1000, 1005]$, нам нужен массив размером всего $6$, а не $1006$. Без сдвига мы бы тратили память впустую на "пустоту" от 0 до 999.

#pagebreak()
== Анализ сложности

Пусть $N$ — количество элементов, $K$ — диапазон значений ($max - min + 1$).

=== Время (Time Complexity)
$ O(N + K) $
Мы проходим по массиву длины $N$ и по массиву подсчета длины $K$ линейно.
Если $K approx N$, то алгоритм работает за линейное время $O(N)$.

=== Память (Space Complexity)
$ O(N + K) $
Требуется память под массив частот ($K$) и выходной массив ($N$).

== Ограничения и применимость

1. *Только целые числа:* Нельзя сортировать `float` или строки (напрямую), так как они не могут быть индексами массива.
2. *Зависимость от диапазона:* Если $K$ (разброс значений) значительно больше $N$ (например, сортируем массив `[1, 1000000]`), алгоритм становится крайне неэффективным по памяти и времени ($O(N^2)$ (при K большем N, K $#math.approx$ $N^2$, будет $O(N + N^2)) => O(N^2)$ или хуже в контексте памяти).
3. *Устойчивость:* Реализация через префиксные суммы является *устойчивой* (Stable). Это критически важно, так как Counting Sort часто используется как подпрограмма в *Radix Sort*.

#pagebreak()
= 7. Цифровая сортировка (Radix Sort)

Алгоритм сортировки, работающий с элементами как с последовательностями цифр (или символов). Не использует сравнения элементов между собой. Является обобщением сортировки подсчетом.

Основная идея: сортировать числа не целиком, а по разрядам (цифрам), используя устойчивую сортировку (обычно Counting Sort) в качестве подпрограммы.

_Параметры:_
- $N$ — количество элементов.
- $b$ — основание системы счисления (base/radix). Например, 10, 2, или 256.
- $d$ — количество разрядов (длина числа).

== Варианты реализации

Существует два принципиально разных подхода к порядку обработки разрядов:

1. *LSD (Least Significant Digit):* Сортировка от младшего разряда к старшему (справа налево).
2. *MSD (Most Significant Digit):* Сортировка от старшего разряда к младшему (слева направо).


== 1. LSD Radix Sort (Младший разряд — первый)

Это классическая, итеративная версия алгоритма. Мы последовательно сортируем массив по последней цифре, затем по предпоследней, и так до первой.

// *Критически важное условие:* Используемая на каждом этапе под-сортировка должна быть *устойчивой (stable)*.
// _Почему?_ Когда мы сортируем по разряду $10^1$ (десятки), мы не должны перемешать порядок, который мы выстроили на этапе $10^0$ (единицы), если десятки у чисел равны.

#note("Важное условие", [
  Используемая на каждом этапе под-сортировка должна быть *устойчивой (stable)*.
  _Почему?_ Когда мы сортируем по разряду $10^1$ (десятки), мы не должны перемешать порядок, который мы выстроили на этапе $10^0$ (единицы), если десятки у чисел равны.
])

=== Пример (LSD)
Массив: `[170, 045, 075, 090, 802, 024, 002, 066]`

1. *Сортируем по единицам (последняя цифра):*
   `[17`*0*`, 09`*0*`, 80`*2*`, 00`*2*`, 02`*4*`, 04`*5*`, 07`*5*`, 06`*6*`]`
   (Обратите внимание: 802 идет перед 002, так как в исходном массиве 802 было раньше. Устойчивость сохранена).

2. *Сортируем по десяткам:*
   `[8`*0*`2, 0`*0*`2, 0`*2*`4, 0`*4*`5, 0`*6*`6, 1`*7*`0, 0`*7*`5, 0`*9*`0]`
   (Сейчас массив отсортирован по последним двум цифрам).

3. *Сортируем по сотням:*
   `[`*0*`02, `*0*`24, `*0*`45, `*0*`66, `*0*`75, `*0*`90, `*1*`70, `*8*`02]`
   *Массив полностью отсортирован.*

=== Реализация LSD (C++)

```cpp
// Вспомогательная функция (Counting Sort по конкретному разряду exp)
void countSortByDigit(vector<int>& arr, int exp) {
    int n = arr.size();
    vector<int> output(n);
    vector<int> count(10, 0); // Система счисления 10

    // 1. Считаем вхождения (digit = (arr[i] / exp) % 10)
    for (int i = 0; i < n; i++)
        count[(arr[i] / exp) % 10]++;

    // 2. Префиксные суммы
    for (int i = 1; i < 10; i++)
        count[i] += count[i - 1];

    // 3. Формируем output (идем с конца для устойчивости!)
    for (int i = n - 1; i >= 0; i--) {
        int digit = (arr[i] / exp) % 10;
        output[count[digit] - 1] = arr[i];
        count[digit]--;
    }

    arr = output;
}

void radixSortLSD(vector<int>& arr) {
    if (arr.empty()) return;
    int max_val = *max_element(arr.begin(), arr.end());

    // Проходим по разрядам: 1, 10, 100... пока exp <= max_val
    for (int exp = 1; max_val / exp > 0; exp *= 10) {
        countSortByDigit(arr, exp);
    }
}
```

#pagebreak()
== 2. MSD Radix Sort (Старший разряд — первый)

Более естественный для человека способ (как поиск слова в словаре). Мы смотрим на первую букву/цифру и раскладываем элементы по "корзинам" (buckets). Внутри каждой корзины рекурсивно запускаем сортировку для следующего разряда.

*Особенности:*
- Рекурсивный алгоритм.
- Может работать с элементами переменной длины (например, строками).
- Не требует устойчивости под-сортировки (так как мы разбиваем массив на независимые подгруппы).

=== Алгоритм MSD
1. Разделить массив на группы (корзины) по значению текущего старшего разряда ($i$).
2. Рекурсивно применить алгоритм к каждой корзине для разряда $i+1$.
3. Соединить корзины обратно.

=== Пример (MSD)
Массив: `[170, 045, 075, 090, 802, 024, 002, 066]`

1. *Смотрим на сотни (разряд 100):*
   - Корзина '0': `[045, 075, 090, 024, 002, 066]` -> *Рекурсия*
   - Корзина '1': `[170]` -> (Один элемент, готово)
   - ...
   - Корзина '8': `[802]` -> (Один элемент, готово)

2. *Рекурсия внутри корзины '0' (смотрим на десятки):*
   - Корзина '0': `[002]`
   - Корзина '2': `[024]`
   - Корзина '4': `[045]`
   - ... и т.д.

#pagebreak()
== Реализация MSD Radix Sort (C++)

В отличие от LSD, здесь мы используем рекурсию.

```cpp
#include <iostream>

int digit_at(int x, int r) { return (int)(x / pow(10, r - 1)) % 10; }

int get_max(int arr[], int len) {
  if (len <= 0) return -INFINITY;
  int max = arr[0];

  for (int i = 0; i < len; ++i) {
    max = std::max(arr[i], max);
  }

  return max;
}

void msd(int arr[], int left, int right, int r) {

  if (right <= left || r == 0) return;

  int cnt[10] = {0};
  for (int i = left; i <= right; ++i) {
    int c = digit_at(arr[i], r);
    cnt[c]++;
  }

  for (int i = 1; i < 10; ++i) {
    cnt[i] += cnt[i - 1];
  }

  int temp[right - left + 1];
  for (int i = right; i >= left; --i) {
    int c = digit_at(arr[i], r);
    temp[cnt[c] - 1] = arr[i];
    cnt[c]--;
  }

  for (int i = left; i <= right; ++i) {
    arr[i] = temp[i];
  }

  // r = 1, | 321 231 431 101 | 122 | 234 | 346
  // cnt = {0, 4, 1, 0, 1, 0, 1};
  // cnt = {0, 4, 5, 5, 6, 6, 7};

  for (int i = 0; i < 10; i++) {
    int gs = (i == 0) ? 0 : cnt[i - 1];
    int ge = cnt[i] - 1;
    if (ge >= gs) {
      msd(arr, left + gs, left + ge, r - 1);
    } 
  }
}

void msd_sort(int arr[], int len) {

  if (len <= 1) return;
  int max = get_max(arr, len);
  int digits = (max == 0) ? 1 : (int)floor(log10(max)) + 1;
  // 2345 -> 3.12312412 -> 3 -> 4

  msd(arr, 0, len - 1, digits);

}

int main() {

  int arr[] = {2100, 1300, 3050, 4000};

  msd_sort(arr, 4);

  for (int i = 0; i < 4; ++i) std::cout << arr[i] << ' ';

}```

=== Сравнение LSD и MSD

#table(
  columns: (1fr, 1fr),
  inset: 10pt,
  align: horizon,
  [*LSD*], [*MSD*],
  [Проще в реализации (цикл).], [Сложнее (рекурсия, управление памятью).],
  [Всегда просматривает *все* разряды у *всех* чисел.], [Может остановиться раньше, если префикс уникален (быстрее на строках).],
  [Удобен для чисел фиксированной длины (`int32`, `int64`).], [Идеален для сортировки строк (lexicographical sort).],
  [Требует устойчивой сортировки на каждом шаге.], [Не требует устойчивости (разбиение на группы).]
)

#pagebreak()
== Анализ сложности (Radix Sort в целом)

Пусть $d$ — количество разрядов, $b$ — основание системы счисления (размер массива подсчета), $N$ — количество элементов.

=== Время (Time Complexity)
$ O(d times (N + b)) $
На каждом из $d$ этапов мы выполняем Counting Sort, который занимает $O(N + b)$.

*Инсайт:* Если мы сортируем `int32`, мы можем выбрать основание $b = 256$ (1 байт). Тогда количество проходов $d = 4$ (так как 4 байта в int).
В этом случае сложность $O(4(N + 256)) approx O(N)$.
Это линейная сортировка!

=== Память (Space Complexity)
$ O(N + b) $
Требуется буфер для выходного массива ($N$) и массив подсчета ($b$).
В MSD версии добавляется память под стек рекурсии.

== Применимость
Radix Sort часто быстрее $O(N log N)$ алгоритмов (QuickSort, MergeSort) на больших массивах чисел или строк, так как не выполняет дорогих операций сравнения. Однако, он проигрывает по кэш-локальности (random access при записи в `output`).

#pagebreak()
= 8. Стек (Stack)

Абстрактная структура данных, работающая по принципу *LIFO (Last In, First Out)* — "последним пришел, первым ушел".

Аналогия из жизни: стопка тарелок. Вы можете положить новую тарелку только наверх и взять тарелку только сверху. Чтобы добраться до нижней, нужно убрать все верхние.

== Визуализация LIFO

#align(center)[
  #let stack-cell(content, color) = rect(
    width: 60pt, 
    height: 30pt, 
    fill: color,
    stroke: (bottom: 1pt, left: 1pt, right: 1pt, top: 0pt), // Открытый верх
    align(center + horizon, content)
  )
  #let arrow-down = text(size: 18pt)[$arrow.b$]
  #let arrow-up = text(size: 18pt)[$arrow.t$]

  #grid(
    columns: 3,
    gutter: 30pt,
    align(center + bottom)[
      *1. Исходный стек* \ \ \
      #stack-cell([*30* (Top)], rgb("#fff9c4"))
      #stack-cell([20], white)
      #stack-cell([10], white)
      #line(start: (-30pt, 0pt), end: (30pt, 0pt), stroke: 2pt) // Дно
    ],
    align(center + bottom)[
      *2. Push(42)* \ \
      #rect(width: 60pt, height: 30pt, fill: rgb("#c8e6c9"), stroke: 1pt, align(center+horizon, [42]))
      #arrow-down \
      #stack-cell([30], white)
      #stack-cell([20], white)
      #stack-cell([10], white)
      #line(start: (-30pt, 0pt), end: (30pt, 0pt), stroke: 2pt)
    ],
    align(center + bottom)[
      *3. Pop()* \
      #rect(width: 60pt, height: 30pt, fill: rgb("#ffcdd2"), stroke: (dash: "dashed"), align(center+horizon, [30]))
      #arrow-up \
      #stack-cell([20 (New Top)], rgb("#fff9c4"))
      #stack-cell([10], white)
      #line(start: (-30pt, 0pt), end: (30pt, 0pt), stroke: 2pt)
    ]
  )
]

== Основные операции

Все операции в стеке выполняются за *константное время* $O(1)$, так как мы работаем только с одним концом структуры (вершиной).

#table(
  columns: (auto, auto, auto),
  inset: 10pt,
  align: horizon,
  [*Операция*], [*Описание*], [*Сложность*],
  [`push(x)`], [Добавляет элемент `x` на вершину стека.], [$O(1)$],
  [`pop()`], [Удаляет элемент с вершины. *Внимание:* в С++ `std::stack::pop` возвращает `void`, а не удаленный элемент.], [$O(1)$],
  [`top()` / `peek()`], [Возвращает значение элемента на вершине, не удаляя его.], [$O(1)$],
  [`empty()`], [Проверяет, пуст ли стек (true/false).], [$O(1)$],
  [`size()`], [Возвращает количество элементов в стеке.], [$O(1)$]
)

== Реализация (на базе динамического массива)

В C++ стандартный адаптер `std::stack` по умолчанию использует `std::deque` (или `std::vector`), закрывая доступ к произвольным индексам.

Пример реализации "вручную" на векторе:

```cpp
template <typename T>
class Stack {
private:
    std::vector<T> data;

public:
    // Добавление элемента
    void push(T val) {
        data.push_back(val);
    }

    // Удаление элемента
    void pop() {
        if (!data.empty()) {
            data.pop_back();
        } else {
            throw std::out_of_range("Stack underflow");
        }
    }

    // Просмотр вершины
    T top() {
        if (!data.empty()) {
            return data.back();
        }
        throw std::out_of_range("Stack is empty");
    }

    bool empty() {
        return data.empty();
    }

    size_t size() {
        return data.size();
    }
};
```

== Области применения

1. *Управление памятью (Call Stack):* Хранение локальных переменных и адресов возврата при вызове функций. Рекурсия работает именно благодаря системному стеку.
2. *Обратная польская запись (RPN):* Вычисление выражений вида `3 4 +` (где операторы идут после операндов).
3. *Скобочные последовательности:* Проверка правильности расстановки скобок `(([]))`.
4. *Обход графов (DFS):* Поиск в глубину использует стек (явно или через рекурсию).
5. *Отмена операций (Undo):* В текстовых редакторах (Ctrl+Z).

#pagebreak()
= 13. Стек на связных списках (Linked List Stack)

Реализация стека (LIFO), использующая односвязный список для хранения элементов.

*Ключевая идея:* Вершина стека (`Top`) соответствует *Голове* (`Head`) списка.
- `push` $->$ Вставка в начало списка.
- `pop` $->$ Удаление первого элемента списка.

*Почему именно в начало?*
В односвязном списке вставка и удаление из начала выполняются за $O(1)$. Удаление с конца (хвоста) требовало бы $O(N)$, так как нам нужно найти предпоследний элемент, чтобы обнулить его `next`.

== Визуализация

#align(center)[
  #let node(val, color) = rect(
    width: 40pt, height: 25pt, fill: color, stroke: 1pt, radius: 3pt,
    align(center+horizon)[#val | $dot$]
  )
  #let arrow = text(size: 14pt)[$arrow.r$]

  #grid(
    columns: 6,
    gutter: 10pt,
    align(center)[*Top / Head* \ $arrow$], [], [], [], [], [],
    node([30], red), arrow, node([20], red), arrow, node([10], red), [$arrow$ *nullptr*]
  )
  #v(5pt)
  #text(style: "italic")[Доступ (Push/Pop) происходит только через Top.]
]

== Реализация (C++)

```cpp
template <typename T>
class LinkedStack {
private:
    struct Node {
        T data;
        Node* next;
        Node(T val, Node* n = nullptr) : data(val), next(n) {}
    };

    Node* head; // Указатель на вершину стека
    size_t sz;

public:
    LinkedStack() : head(nullptr), sz(0) {}

    // Очистка памяти
    ~LinkedStack() {
        while (!empty()) pop();
    }

    // Push: O(1)
    void push(T val) {
        // Создаем узел и сразу направляем его на текущую голову
        head = new Node(val, head);
        sz++;
    }

    // Pop: O(1)
    void pop() {
        if (empty()) throw std::underflow_error("Stack is empty");
        
        Node* oldHead = head;
        head = head->next; // Сдвигаем голову
        delete oldHead;    // Освобождаем память
        sz--;
    }

    // Top: O(1)
    T top() {
        if (empty()) throw std::underflow_error("Stack is empty");
        return head->data;
    }

    bool empty() { return head == nullptr; }
    size_t size() { return sz; }
};
```

== Сравнение: Стек на Векторе vs Стек на Списке

#table(
  columns: (auto, 1fr, 1fr),
  inset: 10pt,
  align: horizon,
  [*Характеристика*], [*Вектор (Array-based)*], [*Список (Linked-based)*],
  [*Выделение памяти*], [Блоками. Редко, но требует копирования всего массива при росте.], [Для каждого элемента отдельно (`new`).],
  [*Стабильность времени*], [Амортизированное $O(1)$. Иногда случаются лаги при ресайзе.], [Строгое $O(1)$. Операция всегда занимает одно и то же время.],
  [*Потребление памяти*], [Экономично (нет указателей), но может быть зарезервировано лишнее место (`capacity`).], [Оверхед на указатели (8-16 байт) для каждого элемента + фрагментация кучи.],
  [*Кэш-локальность*], [Отличная (данные лежат рядом).], [Плохая (узлы разбросаны по памяти).],
)

== Когда использовать Linked Stack?
1. Когда критически важна *гарантированная* скорость операции (Real-time системы), и мы не можем допустить задержку на реаллокацию вектора.
2. Когда размер стека непредсказуем и сильно варьируется.
3. Когда копирование объектов (при ресайзе вектора) слишком дорогое.

#pagebreak()
= 9. Очередь (Queue)

Абстрактная структура данных, работающая по принципу *FIFO (First In, First Out)* — "первым пришел — первым ушел".

Элементы добавляются строго в один конец (хвост/back), а извлекаются строго из другого конца (голова/front).

== Визуализация FIFO

#align(center)[
  #let q-cell(content, color) = rect(
    width: 30pt, 
    height: 30pt, 
    fill: color,
    stroke: 1pt,
    align(center + horizon, content)
  )
  #let arrow-left = text(size: 14pt)[$arrow.l$]

  // Схема
  #grid(
    columns: 6,
    gutter: 5pt,
    align(horizon)[*Выход* \ (Pop) \ $arrow.l$],
    q-cell([10], rgb("#ffcc80")), // Head
    q-cell([20], white),
    q-cell([30], white),
    q-cell([*40*], rgb("#c8e6c9")), // Tail
    align(horizon)[$arrow.l$ \ *Вход* \ (Push)]
  )
  #v(5pt)
  #text(size: 9pt, style: "italic")[Элемент 10 (голова) уйдет следующим. Элемент 40 (хвост) пришел последним.]
]

== Основные операции

Как и в стеке, операции должны выполняться за константное время $O(1)$.

#table(
  columns: (auto, auto, auto),
  inset: 10pt,
  align: horizon,
  [*Операция*], [*Описание*], [*Сложность*],
  [`push(x)` / `enqueue`], [Добавляет элемент `x` в конец очереди.], [$O(1)$],
  [`pop()` / `dequeue`], [Удаляет элемент из начала очереди.], [$O(1)$],
  [`front()` / `peek`], [Возвращает первый элемент (голову), не удаляя его.], [$O(1)$],
  [`back()`], [Возвращает последний элемент (хвост).], [$O(1)$],
  [`empty()`], [Проверяет, пуста ли очередь.], [$O(1)$],
  [`size()`], [Возвращает количество элементов.], [$O(1)$]
)

== Проблема реализации на массиве

Если реализовывать очередь на обычном динамическом массиве (`std::vector`):
- `push` (добавление в конец) работает за $O(1)$.
- `pop` (удаление из начала) требует *сдвига всех остальных элементов* влево на одну позицию. Это стоит $O(N)$.

*Решение:* Использовать *Циклический буфер (Circular Buffer)* или Связный список.

=== Реализация: Циклический буфер (Кольцевая очередь)

Мы используем массив фиксированного размера и два указателя: `head` (начало) и `tail` (конец). Когда указатель доходит до конца массива, он перескакивает на индекс 0 (по модулю размера).

```cpp
template <typename T>
class CircularQueue {
    std::vector<T> data;
    int head = 0;
    int tail = 0;
    int count = 0;
    int capacity;

public:
    CircularQueue(int size) : data(size), capacity(size) {}

    void push(T val) {
        if (count == capacity) throw std::overflow_error("Queue full");
        data[tail] = val;
        tail = (tail + 1) % capacity; // Зацикливание
        count++;
    }

    void pop() {
        if (count == 0) throw std::underflow_error("Queue empty");
        head = (head + 1) % capacity; // Зацикливание
        count--;
    }

    T front() {
        if (count == 0) throw std::underflow_error("Queue empty");
        return data[head];
    }
};
```

_Примечание:_ В C++ стандартный контейнер `std::queue` по умолчанию использует `std::deque` (двусвязную очередь), которая состоит из кусочков (чанков) памяти, что позволяет делать `push` и `pop` с обоих концов за $O(1)$ без реаллокаций всего массива.

== Области применения

1. *Буферизация данных:* Буфер клавиатуры, очередь печати принтера, буферизация видео (потоковая передача).
2. *Обход графов (BFS):* Поиск в ширину использует очередь для хранения вершин, которые нужно посетить.
3. *Планировщики задач:* Очередь процессов в операционной системе (Round Robin).
4. *Паттерны проектирования:* Очереди сообщений (Message Queues) в распределенных системах (Kafka, RabbitMQ) для асинхронной обработки.

#pagebreak()
= 14. Очередь на связных списках (Linked List Queue)

Реализация очереди с использованием односвязного списка. Этот подход обеспечивает динамическое управление памятью (очередь растет по мере необходимости) и гарантирует выполнение всех операций за $O(1)$.

В отличие от стека, где нам достаточно знать только верхушку (`head`), в очереди нам необходимо поддерживать два указателя:
1. `head` (Голова) — для удаления элементов (Pop).
2. `tail` (Хвост) — для добавления элементов (Push).

== Визуализация структуры

Элементы добавляются в хвост и забираются с головы.

#align(center)[
  #let node(val, color) = rect(
    fill: color,
    stroke: 1pt,
    radius: 3pt,
    inset: 8pt,
    [#val $->$]
  )
  
  #grid(
    columns: 5,
    gutter: 10pt,
    align(center)[*Head* \ $arrow.b$],
    [], [], [],
    align(center)[*Tail* \ $arrow.b$],
    
    node([10], rgb("#ffcc80")),
    node([20], white),
    node([30], white),
    node([40], white),
    [null]
  )
  #v(5pt)
  #text(size: 10pt)[Поток данных: $arrow.l$ Pop (удаление) происходит здесь. Push (вставка) происходит здесь $arrow.l$]
]

== Алгоритм операций

=== 1. Push (Enqueue) - Вставка в конец
1. Создать новый узел `newNode`.
2. Если очередь пуста: `head = tail = newNode`.
3. Если не пуста:
   - `tail->next = newNode` (привязываем новый узел к текущему хвосту).
   - `tail = newNode` (перемещаем указатель хвоста на новый узел).

=== 2. Pop (Dequeue) - Удаление из начала
1. Проверить на пустоту (Underflow).
2. Сохранить указатель на удаляемый узел: `temp = head`.
3. Сдвинуть голову: `head = head->next`.
4. *Важный граничный случай:* Если после удаления `head` стал `nullptr` (очередь опустела), необходимо обнулить и `tail` (`tail = nullptr`), иначе он останется указывать на удаленную память (dangling pointer).
5. Удалить `temp` из памяти.

== Реализация (C++)

```cpp
template <typename T>
struct Node {
    T val;
    Node* next;
    Node(T v) : val(v), next(nullptr) {}
};

template <typename T>
class ListQueue {
private:
    Node<T>* head;
    Node<T>* tail;
    size_t sz;

public:
    ListQueue() : head(nullptr), tail(nullptr), sz(0) {}

    // Деструктор для очистки памяти
    ~ListQueue() {
        while (!empty()) pop();
    }

    void push(T val) {
        Node<T>* newNode = new Node<T>(val);
        if (empty()) {
            head = tail = newNode;
        } else {
            tail->next = newNode; // Связываем текущий хвост с новым
            tail = newNode;       // Обновляем хвост
        }
        sz++;
    }

    void pop() {
        if (empty()) throw std::underflow_error("Queue is empty");
        
        Node<T>* temp = head;
        head = head->next;

        if (head == nullptr) {
            tail = nullptr; // Очередь опустела
        }

        delete temp;
        sz--;
    }

    T front() {
        if (empty()) throw std::underflow_error("Queue is empty");
        return head->val;
    }

    bool empty() {
        return head == nullptr;
    }
};
```

== Сравнение реализаций очереди

#table(
  columns: (auto, 1fr, 1fr),
  inset: 10pt,
  align: horizon,
  [*Критерий*], [*На массиве (Circular Buffer)*], [*На списке (Linked List)*],
  [*Память*], [Экономична (нет указателей), но фиксированный размер.], [Оверхед на указатели (`next`) для каждого элемента.],
  [*Скорость*], [Высокая кэш-локальность (данные рядом).], [Низкая кэш-локальность (скачки по памяти).],
  [*Масштабируемость*], [Требует переаллокации ($O(N)$) при переполнении.], [Динамически растет без задержек.],
  [*Сложность операций*], [Всегда $O(1)$.], [Всегда $O(1)$ (но с выделением памяти `new`).]
)

== Вывод
Реализация на списках предпочтительна, когда:
1. Заранее неизвестно количество элементов.
2. Количество элементов сильно варьируется (то пусто, то миллион).
3. Важна гарантия $O(1)$ на вставку (нет пауз на ресайз массива).

#pagebreak()
= 10. Односвязный список (Singly Linked List)

Линейная структура данных, состоящая из узлов (Nodes). Каждый узел содержит:
1. Данные (`data`).
2. Указатель на следующий узел (`next`).

Последний узел указывает на `nullptr`.

*Главное отличие от массива:* Элементы в памяти могут располагаться хаотично (не последовательно). Связь поддерживается только через указатели.

== Визуализация

#align(center)[
  #let node(val) = rect(
    width: 40pt, height: 25pt, stroke: 1pt, radius: 3pt,
    align(center+horizon)[#val | $dot$]
  )
  #let arrow = text(size: 14pt)[$arrow.r$]

  #grid(
    columns: 6,
    gutter: 5pt,
    [*Head* $arrow$], [], [], [], [], [],
    node([12]), arrow, node([99]), arrow, node([37]), [$arrow$ *nullptr*]
  )
]

== Структура узла (C++)

```cpp
template <typename T>
struct Node {
    T data;
    Node* next;
    Node(T val) : data(val), next(nullptr) {}
};
```

== Операции и сложность

#table(
  columns: (auto, auto, 1fr),
  inset: 10pt,
  align: horizon,
  [*Операция*], [*Сложность*], [*Комментарий*],
  [Доступ по индексу], [$O(N)$], [Нужно пройти $N$ раз по `next` от головы.],
  [Вставка в начало], [$O(1)$], [Создать узел, перекинуть `head`.],
  [Вставка в конец], [$O(N)$], [Если нет указателя `tail`. Если есть `tail` — $O(1)$.],
  [Удаление первого], [$O(1)$], [Сдвинуть `head` на `head->next`.],
  [Удаление произвольного], [$O(N)$], [Нужно найти *предыдущий* элемент, чтобы перекинуть его ссылку `next`.],
)

== Плюсы и минусы
+ *Плюсы:* Динамический размер (нет реаллокаций), дешевая вставка/удаление, если известна позиция.
- *Минусы:* Нет произвольного доступа (random access), накладные расходы на хранение указателя (4 или 8 байт на узел), плохая кэш-локальность.

= 11. Двусвязный список (Doubly Linked List)

Улучшенная версия списка, где навигация возможна в обоих направлениях. Каждый узел содержит:
1. Данные (`data`).
2. Указатель на следующий узел (`next`).
3. Указатель на предыдущий узел (`prev`).

== Визуализация

#align(center)[
  #let dnode(val) = rect(
    width: 50pt, height: 25pt, stroke: 1pt, radius: 3pt,
    align(center+horizon)[$dot$ | #val | $dot$]
  )
  #let arrow = text(size: 14pt)[$arrow.l.r$]

  #grid(
    columns: 7,
    gutter: 5pt,
    [*null* $arrow$], dnode([12]), arrow, dnode([99]), arrow, dnode([37]), [$arrow$ *null*]
  )
]

== Структура узла (C++)

```cpp
template <typename T>
struct DNode {
    T data;
    DNode* next;
    DNode* prev;
    DNode(T val) : data(val), next(nullptr), prev(nullptr) {}
};
```

== Ключевые отличия от односвязного

1. *Удаление узла за $O(1)$:*.
   В односвязном списке, чтобы удалить узел `X`, нам нужно иметь указатель на `prev`. В двусвязном списке у `X` уже есть `X->prev`.
   Мы просто делаем:
   ```cpp
   X->prev->next = X->next;
   X->next->prev = X->prev;
   delete X;
   ```

2. *Двусторонний обход:*
   Можно итерироваться с конца в начало (`tail` -> `head`).

3. *Память:*
   Требует больше памяти (два указателя на каждый элемент). Оверхед на 64-битной системе — 16 байт на элемент.

== Сравнение структур (Массив vs Списки)

#table(
  columns: (auto, auto, auto, auto),
  inset: 10pt,
  align: horizon,
  [*Характеристика*], [*Массив*], [*Односвязный*], [*Двусвязный*],
  [*Доступ (Index)*], [$O(1)$], [$O(N)$], [$O(N)$],
  [*Вставка в начало*], [$O(N)$ (сдвиг)], [$O(1)$], [$O(1)$],
  [*Вставка в середину*], [$O(N)$], [$O(1)$ (если есть ptr)], [$O(1)$ (если есть ptr)],
  [*Память (Оверхед)*], [Минимальный], [Средний (1 ptr)], [Высокий (2 ptrs)],
  [*Кэш-локальность*], [Отличная], [Плохая], [Плохая]
)

== Применение в реальных системах
- *Односвязный:* Реализация хеш-таблиц (метод цепочек), простые стеки.
- *Двусвязный:* `std::list` в C++, реализация LRU-кэша, список окон в ОС (Alt+Tab), undo/redo операции.

#pagebreak()
= 12. Циклический список (Circular Linked List)

Разновидность связного списка, в котором последний узел указывает не на `nullptr`, а обратно на первый узел. Таким образом, список образует кольцо.

Может быть как *односвязным* (Singly Circular), так и *двусвязным* (Doubly Circular).

== Визуализация

#align(center)[
  #let node(val) = rect(
    width: 40pt, height: 25pt, stroke: 1pt, radius: 3pt,
    align(center+horizon)[#val | $dot$]
  )
  #let arrow = text(size: 14pt)[$arrow.r$]

  #grid(
    columns: 6,
    gutter: 5pt,
    [*Head* $arrow$], [], [], [], [], [],
    node([A]), arrow, node([B]), arrow, node([C]), [$arrow$ *to A*]
  )
]

== Особенности реализации

Структура узла (`Node`) остается такой же, как в обычном списке. Изменяется логика операций и условие остановки при обходе.

*Главное отличие:* У нас нет `nullptr`. Если мы будем просто идти по `next`, мы попадем в бесконечный цикл.

=== Обход списка (Traversal)

Для обхода используется цикл `do-while`, чтобы гарантированно посетить первый элемент и остановиться, когда снова вернемся к нему.

```cpp
void printList(Node* head) {
    if (!head) return;

    Node* current = head;
    do {
        std::cout << current->data << " ";
        current = current->next;
    } while (current != head);
}
```

=== Вставка элемента

Есть два нюанса вставки (например, в начало):
1. В *односвязном* циклическом списке, чтобы вставить новый элемент перед `head` (сделать его новым `head`), нам нужно найти *последний* элемент (`tail`), чтобы перенаправить его `next` на новый узел. Это занимает $O(N)$.
2. *Оптимизация:* Часто хранят указатель не на `head`, а на `tail`. Тогда:
   - Доступ к началу: `tail->next`.
   - Доступ к концу: `tail`.
   - Вставка в начало и конец становится $O(1)$.

== Двусвязный циклический список

Самая мощная вариация.
- `head->prev` указывает на `tail`.
- `tail->next` указывает на `head`.

Это позволяет двигаться по кругу в любом направлении бесконечно.

== Преимущества и Недостатки

#table(
  columns: (1fr, 1fr),
  inset: 10pt,
  align: horizon,
  [*Преимущества*], [*Недостатки*],
  [Любой узел может быть стартовой точкой для полного обхода.], [Риск бесконечного цикла, если не следить за условием выхода.],
  [Удобно для реализации кольцевых структур (буферов).], [Сложнее реализация вставки/удаления (нужно поддерживать замкнутость).],
  [Быстрый доступ к концу и началу (если храним `tail`).], []
)

== Примеры использования

1. *Планировщик задач (Round Robin):* ОС выделяет квант времени каждому процессу по очереди. Когда список процессов заканчивается, планировщик переходит к первому.
2. *Задача Иосифа Флавия:* Классическая задача на выбывание людей из круга.
3. *Слайдеры изображений / Плейлисты:* Переключение "Next" на последнем элементе возвращает к первому.

#pagebreak()

= 15. Бинарный поиск (Binary Search)

Эффективный алгоритм поиска элемента в *отсортированном* массиве.

Основная идея: на каждом шаге мы сравниваем искомый элемент со *средним* элементом массива. Если они не равны, мы можем отбросить половину массива, так как знаем, что искомый элемент точно не там (благодаря сортировке).

== Визуализация процесса

Ищем число *7* в массиве.

#align(center)[
  #let cell(val, bg) = rect(width: 25pt, height: 25pt, fill: bg, stroke: 1pt, align(center+horizon)[#val])
  #let idx(val) = text(size: 8pt, fill: gray)[#val]

  *Шаг 1: Весь массив* \
  Диапазон `[L, R]`. Средний элемент `mid` = 5. \
  $5 < 7$, значит, все слева нам не нужно. \
  #grid(columns: 9, gutter: 3pt,
    cell([1], white), cell([3], white), cell([5], rgb("#ffcc80")), cell([7], white), cell([9], white), cell([11], white), cell([13], white), cell([15], white), cell([19], white)
  )
  #v(5pt)

  *Шаг 2: Правая половина* \
  Новый диапазон `[L, R]`. Средний элемент `mid` = 11. \
  $11 > 7$, значит, все справа нам не нужно. \
  #grid(columns: 9, gutter: 3pt,
    cell([1], rgb("#eeeeee")), cell([3], rgb("#eeeeee")), cell([5], rgb("#eeeeee")), cell([7], white), cell([9], white), cell([11], rgb("#ffcc80")), cell([13], white), cell([15], white), cell([19], white)
  )
  #v(5pt)

  *Шаг 3: Сужение* \
  Новый диапазон `[L, R]`. Средний элемент `mid` = 7. \
  $7 == 7$. *Найдено!* \
  #grid(columns: 9, gutter: 3pt,
    cell([1], rgb("#eeeeee")), cell([3], rgb("#eeeeee")), cell([5], rgb("#eeeeee")), cell([*7*], rgb("#66bb6a")), cell([9], rgb("#eeeeee")), cell([11], rgb("#eeeeee")), cell([13], rgb("#eeeeee")), cell([15], rgb("#eeeeee")), cell([19], rgb("#eeeeee"))
  )
]

#pagebreak()
== Реализация (C++)

Классический итеративный подход.

```cpp
int binarySearch(const std::vector<int>& arr, int target) {
    int left = 0;
    int right = arr.size() - 1;

    while (left <= right) {
        // Защита от переполнения (integer overflow)
        // Вместо (left + right) / 2
        int mid = left + (right - left) / 2;

        if (arr[mid] == target) {
            return mid; // Элемент найден
        }
        if (arr[mid] < target) {
            left = mid + 1; // Ищем в правой половине
        } else {
            right = mid - 1; // Ищем в левой половине
        }
    }
    return -1; // Не найдено
}
```

=== Критический баг: Overflow
Классическая ошибка новичка (и даже профессионалов):
`int mid = (left + right) / 2;`
Если `left` и `right` — большие положительные числа (близкие к `INT_MAX`), их сумма может переполниться и стать отрицательной.
*Правильный вариант:* `int mid = left + (right - left) / 2;`

== Анализ сложности

=== Время (Time Complexity)
$ O(log_2 N) $
На каждом шаге область поиска уменьшается в 2 раза.
Для 1 000 000 элементов требуется всего $approx 20$ сравнений.
Для 4 миллиардов (`uint32`) — всего 32 сравнения.

=== Память (Space Complexity)
- *Итеративная версия:* $O(1)$.
- *Рекурсивная версия:* $O(log N)$ на стек вызовов.

== Вариации (STL)

В C++ `<algorithm>` есть готовые функции, которые часто полезнее простого поиска:

1. `std::binary_search`: Возвращает `true`/`false`.
2. `std::lower_bound`: Возвращает итератор на *первый* элемент, который $>=$ `target`.
3. `std::upper_bound`: Возвращает итератор на *первый* элемент, который $>$ `target`.

Это позволяет находить диапазоны равных элементов или место для вставки.

== Бинпоиск по ответу (Binary Search on Answer)

Мощная техника решения задач, где нужно найти "минимальное значение X, при котором выполняется условие".

*Условие применимости:* Функция проверки `check(x)` должна быть *монотонной*.
Например: `[False, False, False, True, True, True]`. Нам нужно найти первую `True`.

*Пример:* Задача "Коровы в стойлах" или "Дипломы". Мы не знаем ответ, но можем проверить, подходит ли число $X$, за $O(N)$.
Тогда мы запускаем бинпоиск по диапазону возможных ответов.

*Сложность:* $O(N times log(text("AnswerRange")))$.

```cpp
// Шаблон бинпоиска по ответу (поиск первого True)
// Диапазон [L, R]
while (R - L > 1) {
    int mid = L + (R - L) / 2;
    if (check(mid)) {
        R = mid; // mid подходит, пробуем меньше (левее)
    } else {
        L = mid; // mid не подходит, нужно больше
    }
}
// Ответ в R (или L, зависит от задачи)
```

#pagebreak()
= 16. Пирамида (Binary Heap)

Двоичная куча (пирамида) — это *почти полное* бинарное дерево, которое удовлетворяет *свойству кучи*.

Обычно реализуется на базе массива.

== Основные свойства

1. *Структурное свойство:* Дерево заполняется по уровням слева направо. У него нет "дырок".
2. *Свойство кучи (Heap Property):*
   - Для *Min-Heap:* Значение в любой вершине *меньше или равно* значений её детей. (Корень — минимум).
   - Для *Max-Heap:* Значение в любой вершине *больше или равно* значений её детей. (Корень — максимум).

== Хранение в памяти (Array Mapping)

Так как дерево почти полное, нам не нужны указатели `left` и `right`. Мы используем арифметику индексов.

Нумерация вершин (0-based):
- Корень: индекс $0$.
- Для узла с индексом $i$:
  - *Левый ребенок:* $2i + 1$
  - *Правый ребенок:* $2i + 2$
  - *Родитель:* $(i - 1) / 2$ (целочисленное деление)

#pagebreak()
=== Визуализация (Дерево $arrow.l.r$ Массив)

Рассмотрим *Min-Heap*: `[10, 20, 30, 40, 50]`

#align(center)[
  #let node(val, bg) = rect(
    width: 30pt, height: 30pt, fill: bg, stroke: 1pt, radius: 15pt,
    align(center+horizon)[*#val*]
  )
  #let arr-cell(val, idx) = stack(
    rect(width: 30pt, height: 30pt, stroke: 1pt, align(center+horizon)[#val]),
    align(center)[#text(size: 8pt, fill: gray)[#idx]]
  )

  #grid(
    columns: 2,
    gutter: 50pt,
    align(center)[
      *Логическая структура* \ \
      #node(10, rgb("#fff9c4")) \ // Root
      
      // ИСПОЛЬЗУЕМ ЮНИКОД-КОДЫ НАПРЯМУЮ:
      $ \u{2199} #h(20pt) \u{2198} $ \ 
      
      #grid(columns: 3, gutter: 5pt, node(20, white), [], node(30, white)) \
    ],
    align(center)[
      *Физическая структура (Массив)* \ \
      #grid(
        columns: 5,
        arr-cell(10, 0), arr-cell(20, 1), arr-cell(30, 2), arr-cell(40, 3), arr-cell(50, 4)
      )
      #v(10pt)
      $i=1 ("знач " 20) arrow "Родитель" = (1-1)/2 = 0 ("знач " 10)$
    ]
  )
]

== Основные операции

Вся магия кучи держится на двух процедурах восстановления баланса.

=== 1. Sift Up (Просеивание вверх / Всплытие)
*Когда:* При *вставке* нового элемента.
*Суть:* Мы добавляем элемент в самый конец массива (чтобы сохранить структуру дерева). Если он меньше родителя (в Min-Heap), мы нарушили порядок. Меняем их местами (`swap`). Повторяем, пока элемент не "всплывет" на свое место или не станет корнем.

*Сложность:* $O(log N)$ (высота дерева).

=== 2. Sift Down (Просеивание вниз / Погружение)
*Когда:* При *удалении корня* (extract min/max) или построении кучи.
*Суть:* Мы удаляем корень, а на его место ставим *последний* элемент массива (чтобы не было дырок). Свойство кучи нарушено сверху.
Мы выбираем *меньшего* из детей и меняем элемент с ним местами. Повторяем, пока элемент не "утонет" до нужного уровня.

*Сложность:* $O(log N)$.

#pagebreak()
== Реализация (C++ Min-Heap)

```cpp
class MinHeap {
    vector<int> heap;

    void siftUp(int i) {
        while (i > 0) {
            int parent = (i - 1) / 2;
            if (heap[i] < heap[parent]) {
                swap(heap[i], heap[parent]);
                i = parent;
            } else {
                break;
            }
        }
    }

    void siftDown(int i) {
        while (2 * i + 1 < heap.size()) {
            int left = 2 * i + 1;
            int right = 2 * i + 2;
            int j = left; // Предполагаем, что левый меньше

            // Если правый существует и он меньше левого, выбираем его
            if (right < heap.size() && heap[right] < heap[left]) {
                j = right;
            }

            // Если текущий элемент уже меньше детей — стоп
            if (heap[i] <= heap[j]) break;

            swap(heap[i], heap[j]);
            i = j;
        }
    }

public:
    // Добавление (Insert)
    void push(int x) {
        heap.push_back(x);
        siftUp(heap.size() - 1);
    }

    // Извлечение минимума (Extract Min)
    int pop() {
        int res = heap[0];
        heap[0] = heap.back(); // Ставим последний в корень
        heap.pop_back();       // Удаляем последний
        siftDown(0);           // Чиним порядок
        return res;
    }
};
```

== Построение кучи (Build Heap)

Если у нас уже есть массив чисел, мы можем превратить его в кучу.
1. *Наивный способ:* $N$ раз вызвать `push`. Сложность $O(N log N)$.
2. *Оптимальный способ (Heapify):* Пройтись от середины массива к началу и для каждого элемента вызвать `siftDown`.
   Сложность: *$O(N)$*.
   _Доказательство:_ Элементов на нижних уровнях много, но просеивать их некуда (высота 0). Элементов наверху мало, просеивать глубоко. Сумма ряда сходится к линейной сложности.

=== Математическое обоснование $O(N)$ для Build Heap

Пусть $h$ — высота узла (расстояние до листа).
- Листьев ($h=0$) примерно $N/2$. Для них спуск занимает 0 операций.
- Узлов на высоте $h=1$ примерно $N/4$. Спуск занимает 1 операцию.
- Узлов на высоте $h$ примерно $N / 2^{h+1}$.

Общее количество операций $S$:
$ S = sum_(h=0)^(log N) frac(N, 2^(h+1)) dot h = N sum_(h=0)^(log N) frac(h, 2^(h+1)) $

Вынесем $N/2$ за скобку:
$ S = frac(N, 2) sum_(h=0)^(log N) frac(h, 2^h) $

Это *арифметико-геометрическая прогрессия*. Чтобы оценить сверху, заменим верхний предел на $infinity$ (бесконечный ряд):
$ S < frac(N, 2) sum_(h=0)^(infinity) frac(h, 2^h) $

Известно, что сумма ряда $sum_(k=0)^infinity k x^k = frac(x, (1-x)^2)$ (при $|x| < 1$).
Подставим $x = 1/2$:
$ sum_(h=0)^(infinity) h (1/2)^h = frac(1/2, (1 - 1/2)^2) = frac(0.5, 0.25) = 2 $

Итого:
$ S < frac(N, 2) dot 2 = N $
Суть доказательства в одной фразе:
"Сумма смещений сходится, потому что количество узлов на каждом уровне уменьшается в 2 раза, а глубина увеличивается только линейно (+1). Экспонента в знаменателе побеждает линейный числитель."

*Вывод:* Сложность построения кучи — $O(N)$.

#pagebreak()
== Преимущества и недостатки

#table(
  columns: (1fr, 1fr),
  inset: 10pt,
  [*Плюсы*], [*Минусы*],
  [Поиск минимума/максимума за $O(1)$.], [Поиск *произвольного* элемента за $O(N)$.],
  [Эффективная память (нет указателей, просто массив).], [Слияние двух куч — дорогая операция (если это не биномиальная куча).],
  [Гарантированное $O(log N)$ на вставку и удаление.], []
)


#pagebreak()

= 17. Пирамидальная сортировка (Heap Sort)

Алгоритм сортировки, основанный на структуре данных "Двоичная куча" (Binary Heap).

Основная идея:
1. Превратить входной массив в *Max-Heap* (где корень — максимальный элемент).
2. Поменять местами корень (максимум) с последним элементом массива. Теперь максимальный элемент стоит на своем законном месте в конце.
3. Уменьшить размер кучи на 1 (забыть про последний, уже отсортированный элемент).
4. Восстановить свойство кучи для нового корня (операция `siftDown`).
5. Повторять шаги 2-4, пока куча не исчезнет.

== Визуализация процесса

Массив: `[4, 10, 3, 5, 1]`

#align(center)[
  #let cell(val, fill-c) = rect(width: 25pt, height: 25pt, fill: fill-c, stroke: 1pt, align(center+horizon)[#val])
  #let arrow = text(size: 14pt)[$arrow.b$]

  *1. Построение Max-Heap:* \
  `[10, 5, 3, 4, 1]` (10 — корень, 5 и 3 — дети). \
  #grid(columns: 5, gutter: 3pt, cell(10, rgb("#fff9c4")), cell(5, white), cell(3, white), cell(4, white), cell(1, white))
  #v(5pt) #arrow #v(5pt)

  *2. Swap(Max, Last):* \
  Меняем 10 и 1 местами. 10 "заморожена" (сортирована). \
  #grid(columns: 5, gutter: 3pt, cell(1, rgb("#ffccbc")), cell(5, white), cell(3, white), cell(4, white), cell(10, rgb("#c8e6c9")))
  #v(5pt) $arrow "SiftDown(0)"$ #v(5pt)

  *3. Восстановление кучи (для размера 4):* \
  Новый корень 1 проваливается вниз. Max-Heap восстановлен: `[5, 4, 3, 1]`. \
  #grid(columns: 5, gutter: 3pt, cell(5, rgb("#fff9c4")), cell(4, white), cell(3, white), cell(1, white), cell(10, rgb("#c8e6c9")))
  #v(5pt) #arrow #v(5pt)

  *4. Swap(Max, Last):* \
  Меняем 5 (корень) и 1 (последний в куче). \
  #grid(columns: 5, gutter: 3pt, cell(1, rgb("#ffccbc")), cell(4, white), cell(3, white), cell(5, rgb("#c8e6c9")), cell(10, rgb("#c8e6c9")))
]

== Реализация (C++)

Используем вспомогательную функцию `siftDown` (иногда называемую `heapify`), которую мы разобрали в предыдущей теме.

*Важно:* Для сортировки по возрастанию мы используем *Max-Heap*, чтобы выталкивать большие элементы в конец массива.

```cpp
void siftDown(std::vector<int>& arr, int n, int i) {
    int largest = i;   // Инициализируем наибольший элемент как корень
    int left = 2 * i + 1;
    int right = 2 * i + 2;

    // Если левый дочерний элемент больше корня
    if (left < n && arr[left] > arr[largest])
        largest = left;

    // Если правый дочерний элемент больше, чем самый большой на данный момент
    if (right < n && arr[right] > arr[largest])
        largest = right;

    // Если самый большой элемент не корень
    if (largest != i) {
        std::swap(arr[i], arr[largest]);

        // Рекурсивно просеиваем затронутое поддерево
        siftDown(arr, n, largest);
    }
}

void heapSort(std::vector<int>& arr) {
    int n = arr.size();

    // 1. Построение кучи (Build Heap)
    // Начинаем с последнего родителя и идем до корня
    for (int i = n / 2 - 1; i >= 0; i--)
        siftDown(arr, n, i);

    // 2. Один за другим извлекаем элементы из кучи
    for (int i = n - 1; i > 0; i--) {
        // Перемещаем текущий корень (максимум) в конец
        std::swap(arr[0], arr[i]);

        // Вызываем siftDown на уменьшенной куче (размер i)
        siftDown(arr, i, 0);
    }
}
```

== Анализ сложности

=== Время (Time Complexity)
$ O(N log N) $
- *Build Heap:* $O(N)$ (как мы доказали ранее).
- *Sorting:* Мы делаем $N-1$ извлечений. Каждое извлечение требует `siftDown`, который работает за высоту дерева $O(log N)$.
- Итого: $O(N + N log N) = O(N log N)$.

Это справедливо для лучшего, среднего и худшего случаев. Деградации до $O(N^2)$, как у QuickSort, здесь не бывает.

=== Память (Space Complexity)
$ O(1) $
Алгоритм работает *in-place*. Мы просто переставляем элементы внутри исходного массива.

== Сравнение с конкурентами

#table(
  columns: (auto, 1fr, 1fr, 1fr),
  inset: 10pt,
  align: horizon,
  [*Алгоритм*], [*Heap Sort*], [*Quick Sort*], [*Merge Sort*],
  [*Время (Worst)*], [$O(N log N)$], [$O(N^2)$], [$O(N log N)$],
  [*Память*], [$O(1)$], [$O(log N)$], [$O(N)$],
  [*Устойчивость*], [Нет], [Нет], [Да],
  [*Кэш-локальность*], [Плохая], [Отличная], [Средняя]
)

*Почему Heap Sort часто медленнее Quick Sort на практике?*
Из-за скачков по индексам (`i`, `2i+1`, `2i+2`). Элементы, которые логически связаны в дереве (родитель-ребенок), в массиве могут находиться очень далеко друг от друга. Это приводит к частым промахам кэша процессора (Cache Misses).

#pagebreak()

= 18. Приоритетная очередь (Priority Queue)

Абстрактная структура данных (ADT), похожая на обычную очередь или стек, но с одним ключевым отличием: у каждого элемента есть *приоритет*.

Элемент с *наивысшим* (или наинизшим) приоритетом всегда извлекается первым, независимо от того, когда он был добавлен.

_Аналогия:_ Очередь в травмпункте. Пациента с тяжелой травмой (высокий приоритет) примут раньше, чем того, кто пришел час назад с насморком (низкий приоритет).

== Визуализация (Концепт)

В отличие от FIFO (Queue), здесь нет строгого "хвоста". Элементы попадают в общую кучу, но на выход всегда встает "Король".

#align(center)[
  #let pnode(val, color) = rect(
    width: 30pt, height: 30pt, fill: color, stroke: 1pt, radius: 3pt,
    align(center+horizon)[*#val*]
  )
  
  #grid(
    columns: 2,
    gutter: 20pt,
    align(center)[
      *Вход (Push)* \
      `push(15)`, `push(50)`, `push(10)` \
      $arrow.b$ \
      #rect(width: 100pt, height: 60pt, fill: rgb("#eeeeee"), radius: 5pt, stroke: (dash: "dashed"), 
        align(center+horizon)[*Черный ящик* \ (Сортировка / Куча)]
      )
    ],
    align(center)[
      *Выход (Pop)* \
      (Max-Priority) \
      $arrow.t$ \
      #pnode(50, rgb("#ffcc80")) \
      (Самый большой)
    ]
  )
]

== Реализация

Хотя приоритетную очередь можно реализовать на массиве или связном списке, это неэффективно. Стандартом де-факто является *Двоичная куча (Binary Heap)*.

#table(
  columns: (auto, auto, auto, auto),
  inset: 10pt,
  align: horizon,
  [*Структура*], [*Insert (Push)*], [*Extract Max (Pop)*], [*Peek (Top)*],
  [Несортированный массив], [$O(1)$], [$O(N)$], [$O(N)$],
  [Отсортированный массив], [$O(N)$], [$O(1)$], [$O(1)$],
  [*Двоичная куча*], [$O(log N)$], [$O(log N)$], [$O(1)$]
)

Куча обеспечивает идеальный баланс между скоростью добавления и скоростью извлечения.

== Интерфейс в C++ (STL)

В C++ есть готовый контейнер `std::priority_queue` в библиотеке `<queue>`. По умолчанию это *Max-Heap*.

```cpp
#include <queue>
#include <vector>
#include <iostream>

int main() {
    // 1. Max-Heap (по умолчанию)
    std::priority_queue<int> pq;

    pq.push(10);
    pq.push(30);
    pq.push(20);
    pq.push(5);

    std::cout << pq.top(); // Выведет 30 (максимум)
    pq.pop();              // Удалит 30

    // 2. Min-Heap (для алгоритма Дейкстры и др.)
    // Используем компаратор std::greater
    std::priority_queue<int, std::vector<int>, std::greater<int>> min_pq;

    min_pq.push(10);
    min_pq.push(30);
    
    std::cout << min_pq.top(); // Выведет 10 (минимум)
}
```

== Применение

Приоритетные очереди — сердце многих жадных алгоритмов и системных процессов.

1. *Алгоритм Дейкстры:* Поиск кратчайшего пути в графе. Очередь хранит вершины, отсортированные по текущему расстоянию до них.
2. *Алгоритм Прима:* Поиск минимального остовного дерева (MST).
3. *Сжатие Хаффмана:* Построение оптимального префиксного кода (дерево строится, объединяя символы с наименьшими частотами).
4. *Планировщик задач в ОС:* Процессы с высоким приоритетом получают квант времени процессора раньше фоновых задач.
5. *K-th Largest Element:* Поиск K-го максимального элемента в потоке данных (держим Min-Heap размером K).

== Сложность (Итог)

- *Время:* Все модифицирующие операции занимают $O(log N)$. Получение экстремума — $O(1)$.
- *Память:* $O(N)$ для хранения элементов.

#pagebreak()

= 19. Двоичное дерево поиска (Binary Search Tree - BST)

Это двоичное дерево, обладающее следующим фундаментальным свойством (инвариантом):

Для любого узла $X$:
1. Все ключи в *левом* поддереве меньше ключа $X$.
2. Все ключи в *правом* поддереве больше ключа $X$.
3. Левое и правое поддеревья также являются BST.

_Примечание:_ Обычно предполагается, что ключи уникальны. Если дубликаты разрешены, условие меняется на $<=$ или $>=$.

== Визуализация

Корректное BST:

#align(center)[
  #let node(val, bg) = rect(
    width: 25pt, height: 25pt, fill: bg, stroke: 1pt, radius: 12.5pt,
    align(center+horizon)[*#val*]
  )
  
  // Уровень 1
  #node(8, rgb("#fff9c4")) \
  $ \u{2199} #h(40pt) \u{2198} $ \
  
  // Уровень 2
  #grid(
    columns: 2,
    gutter: 40pt,
    node(3, white), 
    node(10, white)
  )
  
  // Уровень 3
  $ #h(0pt) \u{2199} #h(10pt) \u{2198} #h(60pt) \u{2198} $ \
  #grid(
    columns: 4,
    gutter: 30pt,
    node(1, white), node(6, white), [], node(14, white)
  )
]

*Проверка:*
- Узел 3: слева 1 ($<3$), справа 6 ($>3$). Ок.
- Корень 8: все слева (1, 3, 6) меньше 8. Все справа (10, 14) больше 8. Ок.

#pagebreak()
== Основные операции

Все операции зависят от высоты дерева $h$.

=== 1. Поиск (Search)
Идем от корня. Сравниваем искомый ключ $K$ с текущим узлом.
- $K == "Node.key" arrow$ Нашли.
- $K < "Node.key" arrow$ Идем влево.
- $K > "Node.key" arrow$ Идем вправо.
- Уперлись в `nullptr` $arrow$ Элемента нет.

=== 2. Вставка (Insert)
Аналогично поиску. Спускаемся вниз, пока не найдем свободное место (`nullptr`), и прикрепляем туда новый лист.

=== 3. Удаление (Delete) — Самое сложное
Три случая:
1. *Узел — лист (нет детей):* Просто удаляем ссылку у родителя.
2. *Один ребенок:* Заменяем удаляемый узел его единственным ребенком.
3. *Два ребенка:*
   - Находим *преемника* (Successor) — минимальный элемент в *правом* поддереве.
   - Копируем значение преемника в текущий узел.
   - Рекурсивно удаляем преемника (у него гарантированно нет левого ребенка, см. п. 2).

== Реализация (C++)

```cpp
struct Node {
    int key;
    Node *left, *right;
    Node(int k) : key(k), left(nullptr), right(nullptr) {}
};

Node* search(Node* root, int key) {
    if (root == nullptr || root->key == key)
        return root;
    
    if (key < root->key)
        return search(root->left, key);
    
    return search(root->right, key);
}

Node* insert(Node* root, int key) {
    if (root == nullptr) return new Node(key);

    if (key < root->key)
        root->left = insert(root->left, key);
    else if (key > root->key)
        root->right = insert(root->right, key);
        
    return root;
}
```

== Обходы дерева (Tree Traversals)

Существует три классических способа обойти все узлы (DFS):

1. *Pre-order (Прямой):* Корень $arrow$ Лево $arrow$ Право. (Используется для копирования дерева).
2. *In-order (Центрированный):* Лево $arrow$ Корень $arrow$ Право.
   *Важно:* In-order обход BST дает отсортированную последовательность ключей!
3. *Post-order (Обратный):* Лево $arrow$ Право $arrow$ Корень. (Используется для удаления дерева).

== Анализ сложности

Это критический момент. Сложность операций BST напрямую зависит от его формы (топологии).

#table(
  columns: (auto, auto, auto),
  inset: 10pt,
  align: horizon,
  [*Случай*], [*Высота ($h$)*], [*Сложность операций*],
  [*Лучший / Средний*], [$log_2 N$], [$O(log N)$],
  [*Худший (Вырожденное)*], [$N$], [$O(N)$]
)

=== Проблема деградации
Если вставлять элементы в отсортированном порядке (`1, 2, 3, 4, 5`), BST вырождается в связный список ("палку"). Высота становится $N$, и все преимущества перед обычным массивом теряются.

*Решение:* Использовать *самобалансирующиеся* деревья (AVL, Red-Black, B-Tree), которые гарантируют высоту $log N$.

== Преимущества и недостатки

+ *Плюсы:* Эффективный поиск и вставка (в среднем), поддержка упорядоченности (range queries), динамический размер.
- *Минусы:* В худшем случае работает медленно ($O(N)$), оверхед на хранение указателей, отсутствие произвольного доступа по индексу.

#pagebreak()
= 20. Динамическое программирование (Dynamic Programming)

Метод решения задач, где мы разбиваем сложную проблему на перекрывающиеся подзадачи, решаем каждую один раз и запоминаем ответ ("мемоизация").

== 1. Задача о кузнечике (Grasshopper)

_Условие:_ Кузнечик стоит на ступеньке $0$. Цель — добраться до ступеньки $N$. За один ход можно прыгнуть на расстояние от $1$ до $K$. Сколькими способами можно это сделать?

=== Формула перехода

Пусть $d p[i]$ — количество способов добраться до $i$-й ступеньки.

$ d p[i] = cases(
  1 &"если" i = 0 " (база)",
  sum_(j=1)^k d p[i-j] &"если" i > 0 " (сумма всех предыдущих шагов)"
) $

_Важное условие реализации:_ При суммировании проверяем, что $i - j >= 0$.

=== Реализация (C++)
```cpp
// Сложность: O(N * K)
vector<int> dp(n + 1, 0);
dp[0] = 1;

for (int i = 1; i <= n; ++i) {
    // Перебираем длину прыжка j от 1 до K
    for (int j = 1; j <= k; ++j) {
        if (i - j >= 0) {
            dp[i] += dp[i - j];
        }
    }
}
```

---

== 2. Задача о рюкзаке (0/1 Knapsack Problem)

_Условие:_ Дано $N$ предметов. $i$-й предмет имеет вес $w_i$ и стоимость $v_i$. Рюкзак вмещает вес $W$. Найти максимальную суммарную стоимость предметов, которые влезут в рюкзак.

=== Формула перехода

Пусть $d p[i][c u r r e n t\_w]$ — макс. стоимость, используя подмножество первых $i$ предметов с лимитом веса $c u r r e n t\_w$.

$ d p[i][w] = cases(
  d p[i-1][w] &"если" w_i > w " (предмет не влезает)",
  max(d p[i-1][w], space d p[i-1][w - w_i] + v_i) &"если" w_i <= w
) $

_Пояснение:_ Максимум из двух вариантов:
1. Не берем предмет (остаемся с результатом предыдущего шага).
2. Берем предмет (добавляем его цену $v_i$ к лучшему результату для оставшегося места $w - w_i$).

=== Оптимизация памяти до $O(W)$

Нам не нужна вся матрица, достаточно знать только предыдущую строку. Важно идти по весу в обратном порядке!

```cpp
// Сложность: Time O(N * W), Space O(W)
vector<int> dp(W + 1, 0);

for (int i = 0; i < n; ++i) {        // Перебираем предметы
    for (int w = W; w >= weight[i]; --w) { // Идем с конца!
        dp[w] = max(dp[w], dp[w - weight[i]] + value[i]);
    }
}
```

== 3. Наибольшая возрастающая подпоследовательность (LIS)

_Условие:_ Дан массив чисел. Найти длину самой длинной подпоследовательности, где элементы идут строго по возрастанию.

=== Подход 1: Классическая динамика ($O(N^2)$)

$d p[i]$ — длина НВП, которая *обязательно заканчивается* элементом $a r r[i]$.

$ d p[i] = 1 + max_(0 <= j < i) \{ d p[j] mid(|) a r r[j] < a r r[i] \} $

Если меньших элементов слева нет, то $d p[i] = 1$.

=== Подход 2: Динамика + Бинпоиск ($O(N log N)$)

Чтобы ускорить процесс, мы изменим определение состояния динамики.

Пусть $t a i l s[k]$ — это *минимальное* число, на которое может заканчиваться возрастающая подпоследовательность длины $k+1$.

_Инвариант:_ Массив $t a i l s$ всегда будет отсортирован по возрастанию. Это позволяет использовать бинпоиск.

*Алгоритм:*
Проходим по всем числам $x$ из входного массива:
1. Если $x$ больше всех элементов в $t a i l s$ $arrow$ мы можем удлинить самую длинную последовательность. Дописываем $x$ в конец $t a i l s$.
2. Если $x$ не больше последнего $arrow$ мы ищем в $t a i l s$ первое число, которое $>= x$, и *заменяем* его на $x$.
   _Смысл замены:_ Мы нашли более перспективный (меньший) конец для последовательности той же длины. Это дает нам больше шансов продолжить её в будущем.

*Пример:* `[10, 9, 2, 5, 3, 7, 101, 18]`

#table(
  columns: (auto, auto, auto),
  inset: 5pt,
  align: horizon,
  [*Шаг (число)*], [*Действие*], [*Массив `tails`*],
  [`10`], [Пусто, вставляем], [`[10]`],
  [`9`], [9 < 10, заменяем 10], [`[9]`],
  [`2`], [2 < 9, заменяем 9], [`[2]`],
  [`5`], [5 > 2, добавляем], [`[2, 5]`],
  [`3`], [3 < 5, заменяем 5], [`[2, 3]` (теперь для длины 2 у нас конец 3, это круче чем 5)],
  [`7`], [7 > 3, добавляем], [`[2, 3, 7]`],
  [`101`], [101 > 7, добавляем], [`[2, 3, 7, 101]`],
  [`18`], [18 < 101, заменяем 101], [`[2, 3, 7, 18]`]
)
Длина массива `tails` (4) — это и есть длина НВП.

=== Реализация ($O(N log N)$)

```cpp
int lengthOfLIS(vector<int>& nums) {
    if (nums.empty()) return 0;
    
    vector<int> tails;
    
    for (int x : nums) {
        // lower_bound ищет первый элемент, который >= x
        auto it = std::lower_bound(tails.begin(), tails.end(), x);
        
        if (it == tails.end()) {
            // Если x больше всех, расширяем последовательность
            tails.push_back(x);
        } else {
            // Иначе обновляем существующий конец на более оптимальный (меньший)
            *it = x;
        }
    }
    return tails.size();
}
```

#pagebreak()
= 21. Расстояние Левенштейна (Edit Distance)

Метрика, измеряющая разность между двумя последовательностями символов. Она равна минимальному количеству односимвольных операций, необходимых для превращения одной строки в другую.

#note("Допустимые операции", [
  1. *Вставка (Insertion)* символа.
  2. *Удаление (Deletion)* символа.
  3. *Замена (Substitution)* одного символа на другой.
])

== Формальная постановка (DP)

Пусть даны две строки: $S_1$ длины $M$ и $S_2$ длины $N$.
Мы строим матрицу $D$ размером $(M+1) times (N+1)$, где $D[i][j]$ — это расстояние Левенштейна между *префиксами* строк: $S_1[0...i-1]$ и $S_2[0...j-1]$.

#axiom_block("Рекуррентная формула", [
  1. *База:*
     - $D[i][0] = i$ (превратить префикс длины $i$ в пустую строку = $i$ удалений).
     - $D[0][j] = j$ (превратить пустую строку в префикс длины $j$ = $j$ вставок).
  
  2. *Переход:*
     $ D[i][j] = min(
       D[i-1][j] + 1, quad (text("Удаление из ") S_1),
       D[i][j-1] + 1, quad (text("Вставка в ") S_1),
       D[i-1][j-1] + m quad (text("Замена / Совпадение"))
     ) $
     Где $m = 0$, если $S_1[i-1] == S_2[j-1]$, и $m = 1$, если символы разные.
])

== Визуализация таблицы

Превращаем слово *"КОТ"* в *"СКАТ"*.

#align(center)[
  #table(
    columns: (auto, auto, auto, auto, auto, auto),
    inset: 10pt,
    align: center + horizon,
    stroke: 0.5pt,
    fill: (x, y) => if x==0 or y==0 { rgb("#eeeeee") } else { white },
    
    [], [*""*], [*С*], [*К*], [*А*], [*Т*],
    [*""*], [0], [1], [2], [3], [4],
    [*К*], [1], [1], [1], [2], [3],
    [*О*], [2], [2], [2], [2], [3],
    [*Т*], [3], [3], [3], [3], [*2*]
  )
]
*Ответ:* 2 операции (вставить "С", заменить "О" на "А").

== Реализация (C++)

Классическое решение с матрицей $O(N dot M)$.

```cpp
#include <vector>
#include <string>
#include <algorithm>
#include <iostream>

int levenshteinDist(const std::string& s1, const std::string& s2) {
    int m = s1.length();
    int n = s2.length();

    // Создаем таблицу (m+1) x (n+1)
    std::vector<std::vector<int>> dp(m + 1, std::vector<int>(n + 1));

    // Инициализация базы (нулевая строка и нулевой столбец)
    for (int i = 0; i <= m; ++i) dp[i][0] = i;
    for (int j = 0; j <= n; ++j) dp[0][j] = j;

    // Заполнение
    for (int i = 1; i <= m; ++i) {
        for (int j = 1; j <= n; ++j) {
            int cost = (s1[i - 1] == s2[j - 1]) ? 0 : 1;

            dp[i][j] = std::min({
                dp[i - 1][j] + 1,       // Удаление
                dp[i][j - 1] + 1,       // Вставка
                dp[i - 1][j - 1] + cost // Замена
            });
        }
    }

    return dp[m][n];
}
```

== Оптимизация памяти (Space Optimization)

Заметим, что для вычисления текущей строки $i$ нам нужна только предыдущая строка $i-1$. Хранить всю матрицу не обязательно.

Мы можем использовать только два вектора: `prev` и `curr` (длиной $N+1$).
Это снижает потребление памяти с $O(M dot N)$ до $O(min(M, N))$.

#pagebreak()
```cpp
int levenshteinOptimized(const std::string& s1, const std::string& s2) {
    // Чтобы выделить меньше памяти, берем короткую строку за "столбцы"
    if (s1.length() < s2.length()) return levenshteinOptimized(s2, s1);

    int m = s1.length();
    int n = s2.length();
    
    std::vector<int> prev(n + 1);
    std::vector<int> curr(n + 1);

    // База для нулевой строки
    for (int j = 0; j <= n; ++j) prev[j] = j;

    for (int i = 1; i <= m; ++i) {
        curr[0] = i; // База для нулевого столбца текущей строки
        for (int j = 1; j <= n; ++j) {
            int cost = (s1[i - 1] == s2[j - 1]) ? 0 : 1;
            curr[j] = std::min({
                prev[j] + 1,       // Удаление (сверху)
                curr[j - 1] + 1,   // Вставка (слева)
                prev[j - 1] + cost // Замена (диагональ)
            });
        }
        prev = curr; // Переход к следующему шагу
    }
    return prev[n];
}
```

== Анализ сложности

#table(
  columns: (1fr, 1fr),
  inset: 10pt,
  [*Время (Time)*], [*Память (Space)*],
  [$O(M dot N)$], [$O(M dot N)$ (полная матрица) \ $O(min(M, N))$ (оптимизация)],
)

Здесь $M$ и $N$ — длины строк.

#pagebreak()
= 22. Польская нотация и Парсинг выражений

Компьютеры вычисляют арифметические выражения не так, как люди. Им неудобно искать скобки и учитывать приоритеты операций "на лету".

Для решения этой задачи используются специальные формы записи (нотации) и *Стек*.

== Виды нотаций

Пусть у нас есть выражение: $(A + B) * C$

#table(
  columns: (auto, auto, 2fr),
  inset: 10pt,
  align: horizon,
  [*Название*], [*Пример*], [*Суть*],
  [Инфиксная], [$A + B$], [Знак *между* операндами. Нужны скобки и приоритеты. Привычна для людей.],
  [Префиксная (Польская)], [$+ A B$], [Знак *перед* операндами. Скобки не нужны.],
  [Постфиксная (Обратная Польская - RPN)], [$A B +$], [Знак *после* операндов. Скобки не нужны. Идеальна для стека.]
)

== Алгоритм вычисления RPN (Postfix)

Если выражение уже записано в обратной польской нотации (например, `3 4 + 5 *`), его очень легко вычислить за один проход $O(N)$.

#axiom_block("Алгоритм", [
  Используем *Стек* для чисел. Идем по строке слева направо:
  1. Если встретили *Число* $->$ кладем в стек (`push`).
  2. Если встретили *Оператор* (например, `+`):
     - Достаем два верхних числа из стека: `b = pop()`, `a = pop()`.
     - *Важно:* Первым достается правый операнд ($b$), вторым — левый ($a$).
     - Выполняем операцию: `res = a + b`.
     - Результат кладем обратно в стек (`push(res)`).
  3. В конце в стеке останется одно число — это ответ.
])

=== Визуализация вычисления `3 4 5 * +`
Эквивалент инфиксного: $3 + (4 * 5)$

#align(center)[
  #let stack-state(items) = rect(
    width: 60pt, height: auto, stroke: 1pt, fill: rgb("#e8f5e9"), inset: 5pt,
    align(center, stack(dir: ttb, spacing: 3pt, ..items.map(x => rect(stroke: 0.5pt, width: 100%, [#x]))))
  )
  #let arr = text(size: 14pt)[$arrow.r$]

  #grid(
    columns: 9,
    gutter: 5pt,
    align(center)[*Вход* \ `3`], arr,
    align(center)[*Вход* \ `4`], arr,
    align(center)[*Вход* \ `5`], arr,
    align(center)[*Op* \ `*`], arr,
    align(center)[*Op* \ `+`]
  )
  #v(10pt)
  
  // Состояния стека (ИСПРАВЛЕНО: добавлены запятые в (3,) и (23,))
  #grid(
    columns: 9,
    gutter: 5pt,
    align(bottom, stack-state((3,))), [],        // <--- Запятая здесь!
    align(bottom, stack-state((4, 3))), [],
    align(bottom, stack-state((5, 4, 3))), [],
    align(bottom, stack-state((20, 3))), [],     // 4 * 5 = 20
    align(bottom, stack-state((23,)))            // <--- И здесь! 3 + 20 = 23
  )
]
== Алгоритм Сортировочной станции (Shunting-yard)

Алгоритм Эдсгера Дейкстры для перевода из обычной (инфиксной) записи в RPN.

*Структуры данных:*
1. Очередь вывода (Output Queue) — сюда складываем результат (RPN).
2. Стек операторов (Operator Stack) — временное хранилище для `+`, `*`, `(`.

#axiom_block("Правила перевода", [
  Идем по выражению слева направо:
  1. *Число:* Сразу в Вывод.
  2. *Открывающая скобка `(`:* В Стек.
  3. *Закрывающая скобка `)`:* Выталкиваем (`pop`) операторы из Стека в Вывод, пока не встретим `(`. Скобки уничтожаются.
  4. *Оператор (напр. `*`):*
     - Пока на вершине Стека лежит оператор с *большим или равным* приоритетом, выталкиваем его в Вывод.
     - Кладем текущий оператор в Стек.
  5. *Конец строки:* Выталкиваем всё, что осталось в Стеке, в Вывод.
])

_Приоритеты:_ `*`, `/` (высокий) $>$ `+`, `-` (низкий).

=== Пример перевода $A + B * C$
1. `A` $->$ Вывод `A`.
2. `+` $->$ Стек `+`.
3. `B` $->$ Вывод `A B`.
4. `*` $->$ Стек `+ *` (так как `*` круче `+`, мы его просто кладем сверху).
5. `C` $->$ Вывод `A B C`.
6. Конец $->$ Выталкиваем стек: Вывод `A B C * +`.

#pagebreak()
== Реализация вычисления RPN (C++)

```cpp
#include <stack>
#include <string>
#include <vector>

bool isOperator(const std::string& token) {
    return token == "+" || token == "-" || token == "*" || token == "/";
}

int evalRPN(std::vector<std::string>& tokens) {
    std::stack<int> st;

    for (const string& token : tokens) {
        if (!isOperator(token)) {
            st.push(stoi(token));
        } else {
            int b = st.top(); st.pop();
            int a = st.top(); st.pop();
            
            if (token == "+") st.push(a + b);
            else if (token == "-") st.push(a - b);
            else if (token == "*") st.push(a * b);
            else if (token == "/") st.push(a / b);
        }
    }
    return st.top();
}
```

== Сложность
- *Время:* $O(N)$, где $N$ — длина выражения (один проход).
- *Память:* $O(N)$ для стека и выходной строки.

#pagebreak()
= 23. Динамическое программирование по профилю

Техника для решения задач на решетках (grid), где одно из измерений ($N$) мало, а другое ($M$) может быть большим.

Классическая задача: *Замощение доминошками*.
_Условие:_ Найти количество способов замостить поле $N times M$ плитками размера $1 times 2$ и $2 times 1$.

== Основные понятия

1. *Профиль:* Разрез поля, отделяющий уже обработанные клетки от еще не обработанных.
2. *Маска (состояние):* Битовое число длины $N$, описывающее состояние границы профиля.
   - $1$-й бит: клетка "занята" (торчит доминошка из предыдущего шага).
   - $0$-й бит: клетка "свободна".

== Динамика по изломанному профилю (Broken Profile)

Вместо того чтобы переходить сразу от столбца $j$ к столбцу $j+1$, мы будем двигаться *по одной клетке*.
Пусть мы сейчас рассматриваем клетку $(i, j)$ (строка $i$, столбец $j$).

*Состояние:* `dp[i][j][mask]` — количество способов заполнить всё поле *до* текущей клетки $(i, j)$, при этом граница профиля имеет состояние `mask`.

=== Визуализация профилей

#align(center)[
  #let cell(fill-c, stroke-c) = rect(width: 20pt, height: 20pt, fill: fill-c, stroke: stroke-c)
  
  #grid(
    columns: 6,
    gutter: 3pt,
    align(center + horizon)[*Столбец* \ *Профиль*],
    
    // Сетка (j-1)
    stack(dir: ttb, spacing: 3pt, cell(gray, none), cell(gray, none), cell(gray, none), cell(gray, none)), 
    
    // Текущий профиль (ломаный)
    stack(dir: ttb, spacing: 3pt, 
      cell(gray, none), // i=0 (обработано)
      cell(gray, none), // i=1 (обработано)
      cell(rgb("#ffcc80"), 2pt + red), // i=2 (ТЕКУЩАЯ)
      cell(white, 1pt)  // i=3 (еще нет)
    ),
    
    stack(dir: ttb, spacing: 3pt, cell(white, 1pt), cell(white, 1pt), cell(white, 1pt), cell(white, 1pt)), // j+1
    
    align(horizon)[$arrow.l$ Излом],
    [], []
  )
]

#note("Смысл бита в маске", [
  Рассматривая клетку $(i, j)$:
  - Если $k$-й бит маски = 1: Это значит, что клетка $(i, j)$ (или соседняя) уже занята "хвостом" доминошки, поставленной ранее.
  - Если $k$-й бит маски = 0: Клетка свободна, мы должны принять решение, как её закрыть.
])

== Переходы (Логика)

Пусть мы находимся в $(i, j)$ с маской `mask`. Мы хотим вычислить состояния для следующей клетки (назовем её `next`).
Следующая клетка — это $(i+1, j)$, а если $i=N-1$, то переходим на новую строку $(0, j+1)$.

1. *Если бит `i` в маске равен 1:*
   Клетка $(i, j)$ уже занята (горизонтальной доминошкой слева или вертикальной сверху).
   Мы ничего не ставим. В новую маску этот бит переходит как $0$.
   dp[next][mask $without$ {i}] += dp[curr][mask]

2. *Если бит `i` в маске равен 0:*
   Клетка пуста. Мы *обязаны* её чем-то закрыть. Два варианта:
   - *Положить горизонтально:* Домино займет $(i, j)$ и $(i, j+1)$.
     В новой маске бит $i$ станет $1$ (так как доминошка "вторгается" в следующий столбец).
     dp[next][mask $union$ {i}] += dp[curr][mask]
   
   - *Положить вертикально:* Домино займет $(i, j)$ и $(i+1, j)$.
     Возможно только если $i < N-1$ и клетка $(i+1, j)$ тоже пуста.
     В новой маске биты $i$ и $i+1$ станут $0$.
     dp[next][mask] += dp[curr][mask]

== Реализация (C++)

Оптимизация: используем всего два массива `dp[mask]` и `next_dp[mask]`.

```cpp
#include <vector>
#include <iostream>

long long dominoTiling(int N, int M) {
    // dp[mask] - кол-во способов заполнить профиль с маской
    std::vector<long long> dp(1 << N, 0);
    dp[0] = 1; // Начальное состояние: пустая маска, 1 способ

    for (int j = 0; j < M; ++j) {       // По столбцам
        for (int i = 0; i < N; ++i) {   // По строкам
            std::vector<long long> next_dp(1 << N, 0);

            for (int mask = 0; mask < (1 << N); ++mask) {
                long long count = dp[mask];
                if (count == 0) continue;

                // 1. Если текущая клетка i занята (пришла слева)
                if (mask & (1 << i)) {
                    // Просто пропускаем её, в новой маске бит i = 0
                    next_dp[mask & ~(1 << i)] += count;
                } 
                // 2. Если текущая клетка свободна
                else {
                    // Вариант А: Кладем горизонтально (1x2)
                    // Бит i в следующей маске станет 1 (торчит вправо)
                    next_dp[mask | (1 << i)] += count;

                    // Вариант Б: Кладем вертикально (2x1)
                    if (i + 1 < N && !(mask & (1 << (i + 1)))) {
                        // В broken profile это сложнее, упрощенно:
                        // Мы перепрыгиваем i+1, оставляя маску "чистой" в этих битах
                        // next_dp[mask] += count; // (Концептуально)
                        // Но в реализации часто используют рекурсию.
                        // Код для 2^N * N * M
                        next_dp[mask | (1 << (i + 1))] += count; // (Упрощение)
                    }
                }
            }
            dp = next_dp;
        }
    }
    return dp[0];
}
```

#axiom_block("Правильный алгоритм переходов (Broken Profile)", [
  Чтобы не путаться, перепишем переходы четко.
  `dp[mask]` — состояние перед обработкой клетки $i$.
  `next_dp[mask]` — состояние после обработки клетки $i$.
  
  Перебираем `mask`:
  1. Если `(mask >> i) & 1`: Клетка занята. 
     next_dp[mask "xor" (1 << i)] += dp[mask]
     (Гасим бит, переходим к следующей).
  2. Если `!((mask >> i) & 1)`: Клетка свободна.
     - *Горизонтально:* 
       next_dp[mask xor (1 << i)] += dp[mask]
       (Зажигаем бит, он перенесется на след. столбец).
     - *Вертикально:* \ (если $i+1 < N$ и `!((mask >> (i+1)) & 1)`).
       next_dp[mask xor (1 << (i+1))] += dp[mask]
])

== Анализ сложности

#table(
  columns: (1fr, 1fr),
  inset: 10pt,
  [*Время*], [*Память*],
  [$O(N dot M dot 2^N)$], [$O(2^N)$],
)

Если $N=10, M=100$, то $1000 dot 1024 approx 10^6$ операций. Легко укладывается в 1 секунду.

== Другие задачи на профиль
1. *Гамильтонов путь в узкой решетке:* Найти путь, посещающий все клетки ровно один раз.
2. *Раскраска доски:* Сколькими способами можно раскрасить таблицу в $K$ цветов так, чтобы соседи были разного цвета.
3. *Задача о паркете:* Замощение любыми фигурами (тримино, уголки).

#pagebreak()
= 24. АВЛ-дерево (AVL Tree)

Сбалансированное двоичное дерево поиска (BST), в котором для каждой вершины высота её левого и правого поддеревьев различается не более чем на 1.

*Инвариант АВЛ:* $|h(L) - h(R)| <= 1$ для любого узла.

Это гарантирует, что высота дерева всегда остается $O(log N)$, а значит все операции (поиск, вставка, удаление) выполняются быстро.

== Баланс-фактор
$ b f(v) = h(v.#right) - h(v.#left) $
В АВЛ-дереве $b f(v) in {-1, 0, 1}$.
Если при вставке/удалении баланс нарушается ($|b f| = 2$), выполняются *вращения*.

== Балансировка (Вращения)

Существует 4 типа вращений для восстановления баланса:

1. *Малое левое (LL):* Если перевес справа ($b f = +2$) и правый ребенок тоже "правый" ($b f >= 0$).
2. *Малое правое (RR):* Если перевес слева ($b f = -2$) и левый ребенок тоже "левый" ($b f <= 0$).
3. *Большое левое (RL):* Если перевес справа ($+2$), но правый ребенок "левый" ($-1$). Сначала делаем правое вращение для ребенка, потом левое для узла.
4. *Большое правое (LR):* Если перевес слева ($-2$), но левый ребенок "правый" ($+1$).

#pagebreak()
== Реализация (С++ каркас)

```cpp
struct Node {
    int key;
    Node *left, *right;
    int height;
};

int height(Node* n) { return n ? n->height : 0; }
int getBalance(Node* n) { return n ? height(n->right) - height(n->left) : 0; }

// Обновление высоты после изменений
void fixHeight(Node* n) {
    if (n) n->height = 1 + std::max(height(n->left), height(n->right));
}

// Правое вращение вокруг p
Node* rotateRight(Node* p) {
    Node* q = p->left;
    p->left = q->right;
    q->right = p;
    fixHeight(p);
    fixHeight(q);
    return q; // q стал новым корнем
}

// Балансировка узла
Node* balance(Node* p) {
    fixHeight(p);
    if (getBalance(p) == 2) {
        if (getBalance(p->right) < 0)
            p->right = rotateRight(p->right); // Большое левое (RL)
        return rotateLeft(p);
    }
    if (getBalance(p) == -2) {
        if (getBalance(p->left) > 0)
            p->left = rotateLeft(p->left); // Большое правое (LR)
        return rotateRight(p);
    }
    return p;
}
```

#pagebreak()
= 25. Дерево отрезков (Segment Tree)

Мощная структура данных для выполнения запросов на отрезках (сумма, минимум, максимум, НОД) за $O(log N)$ с возможностью изменения элементов.

*Идея:* Строим бинарное дерево, где каждый узел отвечает за определенный подотрезок массива.
- Корень отвечает за $[0, N-1]$.
- Если узел отвечает за $[L, R]$, то его левый сын — за $[L, M]$, а правый — за $[M+1, R]$, где $M = (L+R)/2$.
- Листья отвечают за конкретные элементы $[i, i]$.

== Визуализация (Sum Tree)
Массив: `[1, 3, 5, 7]`

#align(center)[
  #let node(val, range, bg) = rect(
    width: auto, height: auto, fill: bg, stroke: 1pt, radius: 5pt, inset: 5pt,
    align(center)[*#val* \ #text(size: 8pt)[#range]]
  )
  
  // Уровень 0
  #node(16, "[0-3]", rgb("#fff9c4")) \
  $ \u{2199} #h(60pt) \u{2198} $ \
  
  // Уровень 1
  #grid(columns: 2, gutter: 60pt,
    node(4, "[0-1]", white), node(12, "[2-3]", white)
  )
  $ \u{2199} #h(20pt) \u{2198} #h(40pt) \u{2199} #h(20pt) \u{2198} $ \
  
  // Уровень 2 (Листья)
  #grid(columns: 4, gutter: 15pt,
    node(1, "[0]", white), node(3, "[1]", white), node(5, "[2]", white), node(7, "[3]", white)
  )
]

#pagebreak()
== Основные операции

=== 1. Построение (Build) - $O(N)$
Рекурсивно строим дерево снизу вверх. Значение внутреннего узла = сумма значений детей.

=== 2. Запрос (Query) - $O(log N)$
Чтобы найти сумму на отрезке $[l, r]$, мы спускаемся от корня.
- Если отрезок узла полностью лежит внутри запроса — берем значение.
- Если не пересекается — возвращаем 0.
- Если пересекается частично — рекурсивно идем в детей.

=== 3. Обновление элемента (Point Update) - $O(log N)$
Изменяем значение в листе и пересчитываем значения всех предков до корня.

#pagebreak()
== Реализация (C++ на массиве)

Храним дерево в массиве `t` размера $4N$. Для вершины `v`: левый сын `2*v`, правый `2*v+1`.

```cpp
int t[4 * N]; // Дерево

// v - текущая вершина, tl, tr - границы её отрезка
void build(int a[], int v, int tl, int tr) {
    if (tl == tr) {
        t[v] = a[tl];
    } else {
        int tm = (tl + tr) / 2;
        build(a, 2*v, tl, tm);
        build(a, 2*v+1, tm+1, tr);
        t[v] = t[2*v] + t[2*v+1];
    }
}

// Запрос суммы на [l, r]
int sum(int v, int tl, int tr, int l, int r) {
    if (l > r) return 0;
    if (l == tl && r == tr) return t[v]; // Полное совпадение
    
    int tm = (tl + tr) / 2;
    return sum(2*v, tl, tm, l, min(r, tm)) +
           sum(2*v+1, tm+1, tr, max(l, tm+1), r);
}

// Обновление: a[pos] = new_val
void update(int v, int tl, int tr, int pos, int new_val) {
    if (tl == tr) {
        t[v] = new_val;
    } else {
        int tm = (tl + tr) / 2;
        if (pos <= tm) update(2*v, tl, tm, pos, new_val);
        else update(2*v+1, tm+1, tr, pos, new_val);
        t[v] = t[2*v] + t[2*v+1];
    }
}
```

#pagebreak()
= 26. Групповые обновления (Range Updates)

Что если нам нужно прибавить число $x$ ко всем элементам на отрезке $[L, R]$?
Обычное дерево отрезков будет делать это за $O(N)$, так как нужно обновить все листья.

*Решение:* Ленивое проталкивание (*Lazy Propagation*).

== Идея "Ленивости"
Мы не обновляем все элементы сразу. Мы обновляем только верхушку поддерева, которое полностью входит в запрос, и ставим там пометку ("обещание"): *"Я должен прибавить $x$ всем своим детям, но сделаю это потом"*.

Пометка хранится в массиве `lazy[]`.

== Проталкивание (Push)
Когда мы в следующий раз пойдем в этот узел (для запроса или другого обновления), мы увидим метку, "протолкнем" её детям и сотрем у себя.

#axiom_block("Алгоритм Push", [
  Если в узле `v` есть `lazy[v]`:
  1. Прибавляем `lazy[v]` к детям:
     - `t[2*v] += lazy[v] * len_left`
     - `t[2*v+1] += lazy[v] * len_right`
  2. Передаем "долг" детям:
     - `lazy[2*v] += lazy[v]`
     - `lazy[2*v+1] += lazy[v]`
  3. Обнуляем `lazy[v] = 0`.
])

#pagebreak()
== Реализация Range Update (Add)

```cpp
int lazy[4 * N];

void push(int v, int tl, int tr) {
    if (lazy[v] != 0) {
        int tm = (tl + tr) / 2;
        
        // Применяем изменение к значениям детей (сумма увеличивается на add * len)
        t[2*v] += lazy[v] * (tm - tl + 1);
        lazy[2*v] += lazy[v];
        
        t[2*v+1] += lazy[v] * (tr - tm);
        lazy[2*v+1] += lazy[v];
        
        lazy[v] = 0; // Долг уплачен
    }
}

void update_range(int v, int tl, int tr, int l, int r, int add) {
    if (l > r) return;
    if (l == tl && r == tr) {
        // Полное покрытие: обновляем сам узел и запоминаем lazy
        t[v] += add * (tr - tl + 1);
        lazy[v] += add;
    } else {
        push(v, tl, tr); // Перед спуском обязательно проталкиваем!
        int tm = (tl + tr) / 2;
        update_range(2*v, tl, tm, l, min(r, tm), add);
        update_range(2*v+1, tm+1, tr, max(l, tm+1), r, add);
        t[v] = t[2*v] + t[2*v+1];
    }
}
```

*Важно:* Функцию `push` нужно также добавить в начало функции `sum` (query), чтобы перед чтением данных убедиться, что они актуальны.

== Сложность
И Range Update, и Range Query с ленивым проталкиванием работают за $O(log N)$.